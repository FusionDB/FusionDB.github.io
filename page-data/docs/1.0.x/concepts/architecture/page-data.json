{"componentChunkName":"component---src-templates-documentation-js","path":"/docs/1.0.x/concepts/architecture/","result":{"data":{"pages":{"edges":[{"node":{"id":"a7163ea7-fee2-59e2-93a9-97295900514c","fields":{"path":"/docs/1.0.x/installation/","version":"1.0.x","category":"installation"},"frontmatter":{"title":"Installation","description":"How to install Data Flow","path":"installation/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bd5a11a7-18e7-51b4-b947-2bc07cfbe3a3","fields":{"path":"/docs/1.0.x/installation/local/","version":"1.0.x","category":"installation"},"frontmatter":{"title":"Local Machine","description":"Local Machine Installation Guide","path":"installation/local/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"768f6200-d825-5a92-8fb0-d9d4f8526774","fields":{"path":"/docs/1.0.x/installation/local/docker/","version":"1.0.x","category":"installation"},"frontmatter":{"title":"Docker Compose","description":"Installation using Docker Compose","path":"installation/local/docker","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ed09e37c-0ee2-5a34-9ebd-531a260bbb27","fields":{"path":"/docs/1.0.x/installation/local/docker-customize/","version":"1.0.x","category":"installation"},"frontmatter":{"title":"Docker Compose Customization","description":"Customize the Docker Compose installation","path":"installation/local/docker-customize","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1f4acbf8-19d9-5571-8144-f6bdbb17673e","fields":{"path":"/docs/1.0.x/installation/local/manual/","version":"1.0.x","category":"installation"},"frontmatter":{"title":"Manual","description":"Manual installation","path":"installation/local/manual","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9187e14f-7805-52c1-9523-5662cc0bd05c","fields":{"path":"/docs/1.0.x/installation/cloudfoundry/","version":"1.0.x","category":"installation"},"frontmatter":{"title":"Cloud Foundry","description":"Data Flow Cloud Foundry Installation Guide","path":"installation/cloudfoundry/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a9d29299-0143-5805-9560-ceea1b8cd733","fields":{"path":"/docs/1.0.x/installation/cloudfoundry/cf-cli/","version":"1.0.x","category":"installation"},"frontmatter":{"title":"Cloud Foundry CLI","description":"Install using the Cloud Foundry CLI","path":"installation/cloudfoundry/cf-cli","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e2dd0da6-655a-5dce-9a94-432190a36574","fields":{"path":"/docs/1.0.x/installation/cloudfoundry/cf-local/","version":"1.0.x","category":"installation"},"frontmatter":{"title":"Running locally","description":"Configure the local servers to deploy to Cloud Foundry","path":"installation/cloudfoundry/cf-local","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"aa81741b-4e8f-5fe0-8180-b3b35c334f0a","fields":{"path":"/docs/1.0.x/installation/kubernetes/","version":"1.0.x","category":"installation"},"frontmatter":{"title":"Kubernetes","description":"Data Flow Kubernetes Installation Guide","path":"installation/kubernetes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0bc509b9-db54-5702-a81e-b07664512949","fields":{"path":"/docs/1.0.x/installation/kubernetes/creating-a-cluster/","version":"1.0.x","category":"installation"},"frontmatter":{"title":"Creating a Cluster","description":"Creating a Kubernetes Cluster","path":"installation/kubernetes/creating-a-cluster","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f89cb3e7-dec0-569b-ac11-140d9cfd2d67","fields":{"path":"/docs/1.0.x/installation/kubernetes/helm/","version":"1.0.x","category":"installation"},"frontmatter":{"title":"Helm","description":"Installation using Helm","path":"installation/kubernetes/helm","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6e3e57c0-9b0c-5ba0-81aa-060a1bb1e756","fields":{"path":"/docs/1.0.x/installation/kubernetes/kubectl/","version":"1.0.x","category":"installation"},"frontmatter":{"title":"kubectl","description":"Installation using kubectl","path":"installation/kubernetes/kubectl","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c30d6475-ca22-5473-be63-985c9c083df8","fields":{"path":"/docs/1.0.x/installation/kubernetes/compatibility/","version":"1.0.x","category":"installation"},"frontmatter":{"title":"Kubernetes Compatibility","description":"Compatibility with Kubernetes Versions","path":"installation/kubernetes/compatibility","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4dbf43e6-0df8-53b6-b39f-2c70b6828763","fields":{"path":"/docs/1.0.x/design/","version":"1.0.x","category":"design"},"frontmatter":{"title":"Design","description":"FusionDB design guides","path":"design/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5a2858ae-3b79-55aa-8df1-647ba72aa53e","fields":{"path":"/docs/1.0.x/design/concept/","version":"1.0.x","category":"design"},"frontmatter":{"title":"Concept","description":"design of concept","path":"design/concept/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f58b38f1-eb57-55e6-b728-d8e3eeee0598","fields":{"path":"/docs/1.0.x/design/fql/","version":"1.0.x","category":"design"},"frontmatter":{"title":"SQL Layer","description":"SQL Layer","path":"design/fql/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bd069586-c290-529b-bde5-b4c61a092b74","fields":{"path":"/docs/1.0.x/design/core/","version":"1.0.x","category":"design"},"frontmatter":{"title":"Core Layer","description":"core layer","path":"design/core/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8d26cb10-fc16-58e0-b279-45a91d727de4","fields":{"path":"/docs/1.0.x/design/runtime/","version":"1.0.x","category":"design"},"frontmatter":{"title":"Runtime","description":"runtime","path":"design/runtime/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bc1203e6-5c24-53ef-b7d5-b3991641cdf9","fields":{"path":"/docs/1.0.x/design/developer/","version":"1.0.x","category":"design"},"frontmatter":{"title":"Developer","description":"developer","path":"design/developer/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0c42c162-4438-5ab6-b02f-2b6f41249831","fields":{"path":"/docs/1.0.x/concepts/","version":"1.0.x","category":"concepts"},"frontmatter":{"title":"Concepts","description":"Core Concepts in Spring Cloud Data Flow","path":"concepts/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f47d7680-99d8-579c-9dcd-02996bd06384","fields":{"path":"/docs/1.0.x/concepts/architecture/","version":"1.0.x","category":"concepts"},"frontmatter":{"title":"Architecture","description":"Introduction to Data Flow's Architecture.","path":"concepts/architecture/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"dfc24dc1-1a43-5a42-902f-1026287574e2","fields":{"path":"/docs/1.0.x/concepts/streams/","version":"1.0.x","category":"concepts"},"frontmatter":{"title":"Stream Processing","description":"Stream Processing Framework and Concepts","path":"concepts/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"05f7a75c-e562-586f-8f96-037e7286bfd8","fields":{"path":"/docs/1.0.x/concepts/batch-jobs/","version":"1.0.x","category":"concepts"},"frontmatter":{"title":"Batch Processing","description":"Batch Processing Framework and Concepts","path":"concepts/batch-jobs/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"7303a994-5abf-5a72-b277-45ffcdee4f94","fields":{"path":"/docs/1.0.x/concepts/monitoring/","version":"1.0.x","category":"concepts"},"frontmatter":{"title":"Monitoring","description":"Runtime monitoring of Stream data pipelines","path":"concepts/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c6b97537-de48-5131-817c-887a6fe1737e","fields":{"path":"/docs/1.0.x/concepts/tooling/","version":"1.0.x","category":"concepts"},"frontmatter":{"title":"Tooling","description":"Dashboard and Shell","path":"concepts/tooling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"549f2604-a208-557f-9ddb-97b59fb49d8d","fields":{"path":"/docs/1.0.x/stream-developer-guides/","version":"1.0.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Developer guides ","description":"Learn how to create Streaming data pipelines using prebuilt microservices or create your own.","path":"stream-developer-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5c3d87ba-a23e-5278-949b-45177dd60e7d","fields":{"path":"/docs/1.0.x/stream-developer-guides/getting-started/","version":"1.0.x","category":"stream-developer-guides"},"frontmatter":{"title":"Getting Started","description":"Getting Started with Stream Processing","path":"stream-developer-guides/getting-started/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"30d8143a-a157-5987-aa8d-beb7f891ca54","fields":{"path":"/docs/1.0.x/stream-developer-guides/getting-started/stream/","version":"1.0.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Processing","description":"Create and deploy a streaming data pipeline using prebuilt applications on your Local Machine","path":"stream-developer-guides/getting-started/stream/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bb31aa1b-70a3-511c-b1ef-9f8919098de0","fields":{"path":"/docs/1.0.x/stream-developer-guides/streams/","version":"1.0.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Development","description":"Stream Processing Developer Guide","path":"stream-developer-guides/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d434a513-de03-56c9-97b6-bdfcde73ca8c","fields":{"path":"/docs/1.0.x/stream-developer-guides/streams/standalone-stream-rabbitmq/","version":"1.0.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Application Development on RabbitMQ","description":"Create your own microservices for Stream processing using RabbitMQ and deploy them manually","path":"stream-developer-guides/streams/standalone-stream-rabbitmq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b37a90e1-3d89-515b-a905-415846b703df","fields":{"path":"/docs/1.0.x/stream-developer-guides/streams/standalone-stream-kafka/","version":"1.0.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Application Development on Apache Kafka","description":"Create your own microservices for Stream processing using Apache Kafka and deploy them manually","path":"stream-developer-guides/streams/standalone-stream-kafka/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"7c7daf75-55ef-59f5-9b14-55525f8b6df6","fields":{"path":"/docs/1.0.x/stream-developer-guides/streams/data-flow-stream/","version":"1.0.x","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Processing using Spring Cloud Data Flow","description":"Create and Deploy a Stream Processing Pipeline using Spring Cloud Data Flow","path":"stream-developer-guides/streams/data-flow-stream/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"621b87c8-4882-5c45-874d-e7997d9a4814","fields":{"path":"/docs/1.0.x/stream-developer-guides/streams/stream-other-binders/","version":"1.0.x","category":"stream-developer-guides"},"frontmatter":{"title":"Spring Application Development on other Messaging Middleware","description":"Create your own microservices for Stream processing using other messaging middleware such as Google Pub/Sub, Amazon Kinesis, and Solace JMS","path":"stream-developer-guides/streams/stream-other-binders/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c58d486a-d5d6-55fc-aabd-ba45cb90dfea","fields":{"path":"/docs/1.0.x/stream-developer-guides/programming-models/","version":"1.0.x","category":"stream-developer-guides"},"frontmatter":{"title":"Programming Models","description":"Programming models","path":"stream-developer-guides/programming-models/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"75d3de31-78b4-5b83-9854-d8a02fc374ff","fields":{"path":"/docs/1.0.x/stream-developer-guides/continuous-delivery/","version":"1.0.x","category":"stream-developer-guides"},"frontmatter":{"title":"Continuous Delivery","description":"CD using Skipper","path":"stream-developer-guides/continuous-delivery/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c43a1bb1-f77b-5dbb-9129-f8bbccc3f143","fields":{"path":"/docs/1.0.x/stream-developer-guides/continuous-delivery/cd-basics/","version":"1.0.x","category":"stream-developer-guides"},"frontmatter":{"title":"Continuous Delivery of streaming applications","description":"Continuous Delivery of Streaming applications","path":"stream-developer-guides/continuous-delivery/cd-basics/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"453f1240-1e06-501e-84d6-f5c75294f51b","fields":{"path":"/docs/1.0.x/stream-developer-guides/troubleshooting/","version":"1.0.x","category":"stream-developer-guides"},"frontmatter":{"title":"Troubleshooting","description":"Troubleshooting Streams","path":"stream-developer-guides/troubleshooting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9880ea3d-b6ff-5f0f-b6cc-5e369e6f7532","fields":{"path":"/docs/1.0.x/stream-developer-guides/troubleshooting/debugging-stream-apps/","version":"1.0.x","category":"stream-developer-guides"},"frontmatter":{"title":"Debugging Stream Applications","description":"Debugging Stream Applications outside of Data Flow","path":"stream-developer-guides/troubleshooting/debugging-stream-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3beeb29d-18a6-5f43-90fe-68f959519e78","fields":{"path":"/docs/1.0.x/stream-developer-guides/troubleshooting/debugging-scdf-streams/","version":"1.0.x","category":"stream-developer-guides"},"frontmatter":{"title":"Debugging Stream applications deployed by Data Flow","description":"Debugging Data Flow Stream deployments","path":"stream-developer-guides/troubleshooting/debugging-scdf-streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0eed7576-fb62-53fa-99ea-7e52579622fd","fields":{"path":"/docs/1.0.x/batch-developer-guides/","version":"1.0.x","category":"batch-developer-guides"},"frontmatter":{"title":"Batch Developer guides ","description":"Learn how to create Batch data pipelines using prebuilt microservices or create your own","path":"batch-developer-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"102bd156-c483-51bb-88f5-fa855409c280","fields":{"path":"/docs/1.0.x/batch-developer-guides/getting-started/","version":"1.0.x","category":"batch-developer-guides"},"frontmatter":{"title":"Getting Started","description":"Getting Started with Batch","path":"batch-developer-guides/getting-started/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ea535601-baa1-5bfe-9153-75372559647c","fields":{"path":"/docs/1.0.x/batch-developer-guides/getting-started/task/","version":"1.0.x","category":"batch-developer-guides"},"frontmatter":{"title":"Task Processing","description":"Create and deploy a simple Task pipeline using a prebuilt Task application on your local machine","path":"batch-developer-guides/getting-started/task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"850aaf5b-ad19-5a57-bd92-d05ce20a94f3","fields":{"path":"/docs/1.0.x/batch-developer-guides/batch/","version":"1.0.x","category":"batch-developer-guides"},"frontmatter":{"title":"Batch Development","description":"Batch Developer Guide","path":"batch-developer-guides/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"dec105a5-4b6f-5f71-9351-b196a8277c30","fields":{"path":"/docs/1.0.x/batch-developer-guides/batch/spring-task/","version":"1.0.x","category":"batch-developer-guides"},"frontmatter":{"title":"Simple Task","description":"Create a simple Spring Boot Application using Spring Cloud Task","path":"batch-developer-guides/batch/spring-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9479ba94-433e-52f3-8bd0-3fa5566870dc","fields":{"path":"/docs/1.0.x/batch-developer-guides/batch/spring-batch/","version":"1.0.x","category":"batch-developer-guides"},"frontmatter":{"title":"Spring Batch Jobs","description":"Create a Spring Batch Job","path":"batch-developer-guides/batch/spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"444e21c6-559a-536d-b239-67427a6e6e59","fields":{"path":"/docs/1.0.x/batch-developer-guides/batch/data-flow-simple-task/","version":"1.0.x","category":"batch-developer-guides"},"frontmatter":{"title":"Register and Launch a Spring Cloud Task application using Data Flow","description":"Register and Launch a Spring Cloud Task application using Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c36bf11d-6a72-528f-a52b-76c85db1002e","fields":{"path":"/docs/1.0.x/batch-developer-guides/batch/data-flow-spring-batch/","version":"1.0.x","category":"batch-developer-guides"},"frontmatter":{"title":"Register and launch a Spring Batch application using Data Flow","description":"Register and launch a Spring Batch application using Data Flow","path":"batch-developer-guides/batch/data-flow-spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8229c50e-ed25-5c35-b801-74ddb159ad25","fields":{"path":"/docs/1.0.x/batch-developer-guides/batch/data-flow-composed-task/","version":"1.0.x","category":"batch-developer-guides"},"frontmatter":{"title":"Create and launch a Composed Task using Data Flow","description":"Create and launch a Composed Task using Data Flow","path":"batch-developer-guides/batch/data-flow-composed-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6a82f60f-8635-5b10-a8c0-919bb4e421b7","fields":{"path":"/docs/1.0.x/batch-developer-guides/batch/data-flow-simple-task-kubernetes/","version":"1.0.x","category":"batch-developer-guides"},"frontmatter":{"title":"Deploying a task application on Kubernetes with Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Kubernetes using Spring Cloud Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task-kubernetes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e3203d7d-4257-57da-91ce-fb162be67962","fields":{"path":"/docs/1.0.x/batch-developer-guides/batch/data-flow-simple-task-cloudfoundry/","version":"1.0.x","category":"batch-developer-guides"},"frontmatter":{"title":"Deploying a task application on Cloud Foundry using Spring Cloud Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Cloud Foundry using Spring Cloud Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task-cloudfoundry/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4b4804df-3108-5a77-9a1b-9acf3d7993c1","fields":{"path":"/docs/1.0.x/batch-developer-guides/continuous-deployment/","version":"1.0.x","category":"batch-developer-guides"},"frontmatter":{"title":"Continuous Deployment","description":"Continuous Deployment for task applications","path":"batch-developer-guides/continuous-deployment/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"42f40244-c1c6-54d0-9f55-19a6abeb1e18","fields":{"path":"/docs/1.0.x/batch-developer-guides/continuous-deployment/cd-basics/","version":"1.0.x","category":"batch-developer-guides"},"frontmatter":{"title":"Continuous Deployment of task applications","description":"This section discusses how to use Continuous Deployment of Tasks in SCDF","path":"batch-developer-guides/continuous-deployment/cd-basics/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"aff8ddff-db2c-58b7-8318-eb71b0345870","fields":{"path":"/docs/1.0.x/batch-developer-guides/troubleshooting/","version":"1.0.x","category":"batch-developer-guides"},"frontmatter":{"title":"Troubleshooting","description":"Troubleshooting Batch Jobs","path":"batch-developer-guides/troubleshooting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9306cc1f-4df5-5f11-9c91-38630700a788","fields":{"path":"/docs/1.0.x/batch-developer-guides/troubleshooting/debugging-task-apps/","version":"1.0.x","category":"batch-developer-guides"},"frontmatter":{"title":"Debugging Batch applications","description":"Debugging Batch applications","path":"batch-developer-guides/troubleshooting/debugging-task-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ac39f173-da48-5471-af07-8cc0ae79c5a6","fields":{"path":"/docs/1.0.x/batch-developer-guides/troubleshooting/debugging-scdf-tasks/","version":"1.0.x","category":"batch-developer-guides"},"frontmatter":{"title":"Debugging Batch applications deployed by Data Flow","description":"Debugging Batch applications deployed by Data Flow","path":"batch-developer-guides/troubleshooting/debugging-scdf-tasks/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f756eab0-a1c7-5519-91b8-b756b66427d5","fields":{"path":"/docs/1.0.x/feature-guides/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Feature guides","description":"High level overview of Data Flow Features","path":"feature-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a6130b0a-97c5-58c9-a992-8a913de8363c","fields":{"path":"/docs/1.0.x/feature-guides/general/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"General","description":"General Features in Data Flow","path":"feature-guides/general/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2da44c23-5791-5f72-98e7-b06ad935f91a","fields":{"path":"/docs/1.0.x/feature-guides/general/application-metadata/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Application Metadata","description":"Create and use application properties metadata","path":"feature-guides/general/application-metadata/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9595e887-0056-5bf5-81fe-af8041b4f37a","fields":{"path":"/docs/1.0.x/feature-guides/streams/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Streams","description":"Stream Features in Data Flow","path":"feature-guides/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"beec2961-d478-51c8-a16d-1f8381bc054a","fields":{"path":"/docs/1.0.x/feature-guides/streams/deployment-properties/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Deployment Properties","description":"Initiate a stream deployment with deployment property overrides","path":"feature-guides/streams/deployment-properties/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1bc3d5fc-8110-5fdd-80cd-6e943f6cbf84","fields":{"path":"/docs/1.0.x/feature-guides/streams/function-composition/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Composing Functions","description":"Daisy-chain Java functions in an existing Spring Cloud Stream application","path":"feature-guides/streams/function-composition/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a2850433-5830-5d6b-929e-ef00b1ffe2dd","fields":{"path":"/docs/1.0.x/feature-guides/streams/named-destinations/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Named Destinations","description":"Use the Named Destinations to interact with the Topics/Queues directly","path":"feature-guides/streams/named-destinations/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0b1fdd2b-63ee-55e4-ac39-c1af84975009","fields":{"path":"/docs/1.0.x/feature-guides/streams/monitoring/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Stream Monitoring","description":"Monitoring streaming data pipelines with Prometheus and InfluxDB","path":"feature-guides/streams/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1f7e22c3-dd60-59eb-89aa-d32ff0aa146e","fields":{"path":"/docs/1.0.x/feature-guides/streams/stream-application-dsl/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Stream Application DSL","description":"Learn how to use the Stream Application DSL","path":"feature-guides/streams/stream-application-dsl/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8f9cb8a7-8f95-5e41-9b7b-64f217f9ad53","fields":{"path":"/docs/1.0.x/feature-guides/streams/labels/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Labeling Applications","description":"Label the stream applications to uniquely interact with them","path":"feature-guides/streams/labels/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"dadb6660-e6bd-5e0a-a0cc-5ffd6c97ac39","fields":{"path":"/docs/1.0.x/feature-guides/streams/application-count/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Application Count","description":"Initiate stream deployment with multiple application instances","path":"feature-guides/streams/application-count/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"22c21f61-5468-5a3c-9b95-944b4587bb94","fields":{"path":"/docs/1.0.x/feature-guides/streams/fanin-fanout/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Fan-in and Fan-out","description":"Publish and subscribe to multiple destinations using the fan-in and fan-out capabilities","path":"feature-guides/streams/fanin-fanout/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a1bcdf2b-cf7d-5ba3-be0f-717da33a7598","fields":{"path":"/docs/1.0.x/feature-guides/streams/partitioning/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Data Partitioning","description":"Learn more about data partitioning support to build stateful streaming data pipelines","path":"feature-guides/streams/partitioning/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2b2f20ee-7207-5d37-9938-46f11ebfbb35","fields":{"path":"/docs/1.0.x/feature-guides/streams/scaling/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Scaling","description":"Scaling streaming data pipeline with Spring Cloud Data Flow","path":"feature-guides/streams/scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e48190e2-51d0-5e97-be89-ddec511e3c8e","fields":{"path":"/docs/1.0.x/feature-guides/streams/java-dsl/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Java DSL","description":"Programmatically create streams using the Java DSL","path":"feature-guides/streams/java-dsl/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"74c1c9cc-59a1-56e3-84b0-d37c2cc01644","fields":{"path":"/docs/1.0.x/feature-guides/streams/taps/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Tapping a Stream","description":"Create a stream from another stream without interrupting the data processing","path":"feature-guides/streams/taps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c0fc1912-0647-5493-8682-ad556ca18123","fields":{"path":"/docs/1.0.x/feature-guides/batch/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Batch","description":"Batch Features in Data Flow","path":"feature-guides/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ef7306d1-1bb4-5c4f-a6d4-6a1916fb9936","fields":{"path":"/docs/1.0.x/feature-guides/batch/deployment-properties/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Deployment Properties","description":"Initiate a Batch deployment with deployment property overrides","path":"feature-guides/batch/deployment-properties/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0bf731f8-f15b-5fa5-93c6-66a1a50a217e","fields":{"path":"/docs/1.0.x/feature-guides/batch/scheduling/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Scheduling Batch Jobs","description":"Learn how to schedule Batch Jobs","path":"feature-guides/batch/scheduling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8634ea59-9d3a-5a8c-893b-d2410db40a50","fields":{"path":"/docs/1.0.x/feature-guides/batch/partitioning/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Remote Partitioned Batch Job","description":"Learn more about partitioning support for Batch Jobs","path":"feature-guides/batch/partitioning/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b1fe2d75-240a-5805-9e57-d7a22fd00967","fields":{"path":"/docs/1.0.x/feature-guides/batch/monitoring/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Task Monitoring","description":"Monitoring task data pipelines with InfluxDB","path":"feature-guides/batch/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"be9476c4-fca5-5462-bd55-1fec11d57015","fields":{"path":"/docs/1.0.x/feature-guides/batch/restarting/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Restarting Batch Jobs","description":"Learn how to restart Batch Jobs","path":"feature-guides/batch/restarting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3ae5c6a5-8daa-5e78-ac01-62e5055f259d","fields":{"path":"/docs/1.0.x/feature-guides/batch/composed-task/","version":"1.0.x","category":"feature-guides"},"frontmatter":{"title":"Composed Tasks","description":"Learn how to create and manage composed tasks","path":"feature-guides/batch/composed-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c9418073-406e-5381-9caa-c1f4f5de3bd0","fields":{"path":"/docs/1.0.x/recipes/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Recipes","description":"Recipes that help solve some common use-cases","path":"recipes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c1e87d44-5cad-57de-9697-b938aacb6787","fields":{"path":"/docs/1.0.x/recipes/polyglot/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Polyglot","description":"Using multiple programming languages","path":"recipes/polyglot/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6fcdc3d3-3437-555c-bd6c-ae9a555d7cdc","fields":{"path":"/docs/1.0.x/recipes/polyglot/processor/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Python Stream Processor","description":"Python Application as a Data Flow Stream Processor","path":"recipes/polyglot/processor/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e2182467-6e67-518d-a081-7bac0ab112bf","fields":{"path":"/docs/1.0.x/recipes/polyglot/task/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Python Task","description":"Create and Deploy a Python Task","path":"recipes/polyglot/task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5bbaaf56-042c-519c-bf0c-479b8296ca3f","fields":{"path":"/docs/1.0.x/recipes/polyglot/app/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Python Application","description":"Create and Deploy a Python Application in a Stream","path":"recipes/polyglot/app/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ab2e3101-f6b7-585f-aa51-f589b6cd53f1","fields":{"path":"/docs/1.0.x/recipes/rabbitmq/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"RabbitMQ","description":"RabbitMQ","path":"recipes/rabbitmq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e7ac46b6-d8da-5011-95cd-3bd677878f2d","fields":{"path":"/docs/1.0.x/recipes/rabbitmq/rabbit-source-sink/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"RabbitMQ as Source and Sink","description":"RabbitMQ as Source and Sink + RabbitMQ binder","path":"recipes/rabbitmq/rabbit-source-sink/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"beaa0cd8-6417-5886-92d1-f86fb0fb9be9","fields":{"path":"/docs/1.0.x/recipes/kafka/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Apache Kafka","description":"Kafka","path":"recipes/kafka/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"926fbf39-6a6c-51ba-8ce1-0c88b1583941","fields":{"path":"/docs/1.0.x/recipes/kafka/ext-kafka-cluster-cf/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"External Kafka Cluster","description":"Connect to an external Kafka Cluster from Cloud Foundry","path":"recipes/kafka/ext-kafka-cluster-cf/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5e8ac125-4c49-5506-b8b7-96fd7eb225a0","fields":{"path":"/docs/1.0.x/recipes/kinesis/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Amazon Kinesis","description":"Amazon Kinesis","path":"recipes/kinesis/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"85cce150-f34f-5e56-8d1c-474e13a59c60","fields":{"path":"/docs/1.0.x/recipes/kinesis/simple-producer-consumer/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Amazon Kinesis Binder","description":"A sample of Spring Cloud Stream + Amazon Kinesis Binder in action","path":"recipes/kinesis/simple-producer-consumer/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"17cf6afa-cacd-51b1-a38d-269c327433bd","fields":{"path":"/docs/1.0.x/recipes/multi-platform-deployment/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Multiple Platform Deployments","description":"Multiple Platform Deployments","path":"recipes/multi-platform-deployment/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3cecd815-ef4e-5849-a3bd-8244340450c3","fields":{"path":"/docs/1.0.x/recipes/multi-platform-deployment/multiple-platform-accounts/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Role of Multiple Platform Deployments","description":"A walk-through of multiple platform requirements and the configurations for Cloud Foundry and Kubernetes","path":"recipes/multi-platform-deployment/multiple-platform-accounts","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"24631eae-3b20-587f-ad1e-ec09f0a70b92","fields":{"path":"/docs/1.0.x/recipes/scaling/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Scaling","description":"Prometheus and Data Flow to autoscale streaming data pipelines","path":"recipes/scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a8642f26-c053-56c4-9d54-d98f6d52e6a2","fields":{"path":"/docs/1.0.x/recipes/scaling/manual-scaling/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Manual Scaling","description":"Scale applications using SCDF Shell","path":"recipes/scaling/manual-scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ab0eae66-b0a8-5173-9f37-3f7f7954a307","fields":{"path":"/docs/1.0.x/recipes/scaling/autoscaling/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Autoscaling","description":"Autoscale streaming data pipeline with SCDF and Prometheus","path":"recipes/scaling/autoscaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4bdd938e-edb1-5932-b003-c44f6b7b7362","fields":{"path":"/docs/1.0.x/recipes/batch/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Batch","description":"Using Spring Cloud Data Flow with Spring Batch","path":"recipes/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5f7e4b28-d4d4-5db2-b8f6-5cf784348f99","fields":{"path":"/docs/1.0.x/recipes/batch/batch-only-mode/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Batch-only Mode","description":"Set up Spring Cloud Data Flow to use only batch and not streams","path":"recipes/batch/batch-only-mode/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"05184c9b-cfba-5ba5-9989-bfa5fcdff52b","fields":{"path":"/docs/1.0.x/recipes/batch/sftp-to-jdbc/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"SFTP to JDBC","description":"Ingest Files from SFTP to a JDBC data store using Data Flow and Spring Batch","path":"recipes/batch/sftp-to-jdbc/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3b1f9b94-4bb5-5a7e-95b4-406de275f1e3","fields":{"path":"/docs/1.0.x/recipes/functional-apps/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Functional Applications","description":"Using Functional Approach in Spring Cloud Stream applications","path":"recipes/functional-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"09de46bd-144f-515c-8ceb-fe299888efa8","fields":{"path":"/docs/1.0.x/recipes/functional-apps/scst-function-bindings/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Functional Applications","description":"Configuring the Spring Cloud Stream Functional applications","path":"recipes/functional-apps/scst-function-bindings/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2219bb7b-fe37-58d5-983b-c8f87bc826db","fields":{"path":"/docs/1.0.x/recipes/cloud-providers/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"Cloud Providers","description":"Using functionality provided by cloud providers","path":"recipes/cloud-providers/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e6479091-7b1b-5c7c-beab-754b1d921760","fields":{"path":"/docs/1.0.x/recipes/cloud-providers/gke-regional-clusters/","version":"1.0.x","category":"recipes"},"frontmatter":{"title":"GKE Regional Clusters","description":"Deploying Spring Cloud Data Flow to a GKE Regional Cluster","path":"recipes/cloud-providers/gke-regional-clusters/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3ed354bf-b384-5e0f-aa07-7ccb41a8dc84","fields":{"path":"/docs/1.0.x/resources/","version":"1.0.x","category":"resources"},"frontmatter":{"title":"Resources","description":"Sample Applications, References Docs, Videos, Blogs...","path":"resources/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"dbb3d525-e9e5-5de6-8a1e-3de452708798","fields":{"path":"/docs/1.0.x/resources/reference-docs/","version":"1.0.x","category":"resources"},"frontmatter":{"title":"Reference Documentation","description":"Collection of reference guides for Spring Cloud Data Flow","path":"resources/reference-docs/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ba1fee96-388f-5785-bd61-2c828c0380b4","fields":{"path":"/docs/1.0.x/resources/samples/","version":"1.0.x","category":"resources"},"frontmatter":{"title":"Samples","description":"Collection of samples","path":"resources/samples/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bac2f165-b025-53f8-aa62-9218cb36cc52","fields":{"path":"/docs/1.0.x/resources/faq/","version":"1.0.x","category":"resources"},"frontmatter":{"title":"Frequently Asked Questions","description":"","path":"resources/faq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"310d895e-f2b0-51e9-ac91-5b2b527c8a6e","fields":{"path":"/docs/1.0.x/applications/","version":"1.0.x","category":"applications"},"frontmatter":{"title":"Applications","description":"Using stream and task applications","path":"applications/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"438e7b00-2573-56f0-a213-853e846f5e60","fields":{"path":"/docs/1.0.x/applications/pre-packaged/","version":"1.0.x","category":"applications"},"frontmatter":{"title":"Pre-packaged Applications","description":"Pre-packaged stream and task applications","path":"applications/pre-packaged","meta_title":null,"meta_description":null,"keywords":["application","pre-packaged"]}}}]},"page":{"html":"<h1 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h1>\n<p>This guide explains the main concepts of Data Flow's architecture:</p>\n<ul>\n<li>Data Flow's Server Components.</li>\n<li>The types of applications the server components can deploy for Streams and Batch Jobs.</li>\n<li>The microservice architecture of the deployed applications and how that is defined by using a DSL.</li>\n<li>The platforms where they are deployed.</li>\n</ul>\n<p>Other sections of the guide explain:</p>\n<ul>\n<li>How the Server Components are secured and the tooling used to interact with them.</li>\n<li>Runtime monitoring of Streaming data pipelines.</li>\n<li>The Spring projects that you can use to develop Stream and Batch data pipelines.</li>\n</ul>\n<h2 id=\"server-components\" style=\"position:relative;\"><a href=\"#server-components\" aria-label=\"server components permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Server Components</h2>\n<p>Data Flow has two main components:</p>\n<ul>\n<li>Data Flow Server</li>\n<li>Skipper Server</li>\n</ul>\n<p>The main entry point to access Data Flow is through the RESTful API of the Data Flow Server.\nThe Web Dashboard is served from the Data Flow Server. The Data Flow Server and the Data Flow Shell application both communicate through the web API.</p>\n<p>The servers can be run on several platforms: Cloud Foundry, Kubernetes, or on your Local machine.\nEach server stores its state in a relational database.</p>\n<p>The following image shows a high-level view of the architecture and the paths of communication:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 582px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 53.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB0UlEQVQoz41TCW7bMBDU4/uLPqAf6A+KtugVRHGayvURy6IoiRSpW7LOyZKtUxhwkC6wWHG4u5w95EzzjGGeMGPBSNaokWVZrJ3JTnQ3LX/0jJ/P5m5c5mfcCXSKJM+wCXxEmUKUa+RtYy9P44hHweEnpCKympQZ6v6EY5pY/EgYo2+Dm5QOkwL7/R6u62K73SISCXac4dR2aMcBfsTwcH+H1crFYb+jxxX0qUUsE3i/fuLH92+IQ0ZkUqpuhsMLDZ9eYMTUTwUYXZhETV3jkQVgxEBJCRYGyKiCwDBNIsQUI4VASA9qJcEpzrTA4eSUljl4KiGodFHk1lZliZDYcmJyF37GW/cNboOPkFmBmEhIleIm+GDx+/ArZF7Y/juMWCmlsN5sEMUxBWgciAF12TI9xCFuj1/w3nsHj61sn1VXI6D+3fifLP47fAAjlhMNx5FVgbQuobsGqqkg6NxPox3KQDYh9qqqkKgcmoalyccMS1Q5VVZe4HbKeEHOa2AkpR5yHqJtmgsf00ODd237HOMsf3frmlqWw4D1em03IOQcM03SSN/38DwP290WPIr+7eFrDEcqj1MiQWy01lfxLMv+L+HZqes6VNTHabr8i67hT2M8RwIinrhLAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/19e89c2894aa4586aec3336ac4e6954b/507e6/arch-overview.webp 200w,\n/static/19e89c2894aa4586aec3336ac4e6954b/28a80/arch-overview.webp 400w,\n/static/19e89c2894aa4586aec3336ac4e6954b/5105f/arch-overview.webp 582w\"\n              sizes=\"(max-width: 582px) 100vw, 582px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/19e89c2894aa4586aec3336ac4e6954b/36ca5/arch-overview.png 200w,\n/static/19e89c2894aa4586aec3336ac4e6954b/a3397/arch-overview.png 400w,\n/static/19e89c2894aa4586aec3336ac4e6954b/0fd20/arch-overview.png 582w\"\n            sizes=\"(max-width: 582px) 100vw, 582px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/19e89c2894aa4586aec3336ac4e6954b/0fd20/arch-overview.png\"\n            alt=\"Spring Cloud Data Flow Architecture Overview\"\n            title=\"Spring Cloud Data Flow Architecture Overview\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n    </span></p>\n<h3 id=\"data-flow-server\" style=\"position:relative;\"><a href=\"#data-flow-server\" aria-label=\"data flow server permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data Flow Server</h3>\n<p>The Data Flow Server is responsible for</p>\n<ul>\n<li>Parsing the Stream and Batch Job definitions based on a Domain Specific Language (DSL - Domain-Specific Language).</li>\n<li>Validating and persisting Stream, Task, and Batch Job definitions.</li>\n<li>Registering artifacts such as .jar and docker images to names used in the DSL.</li>\n<li>Deploying Batch Jobs to one or more platforms.</li>\n<li>Delegating Job scheduling to a platform.</li>\n<li>Querying detailed Task and Batch Job execution history.</li>\n<li>Adding configuration properties to Streams that configure messaging inputs and outputs as well as passing along deployment properties (such as initial number of instances, memory requirements and data partitioning).</li>\n<li>Delegating Stream Deployment to Skipper.</li>\n<li>Auditing actions (such as Stream create, deploy, undeploy and Batch create, launch, delete).</li>\n<li>Providing Stream and Batch Job DSL tab-completion features.</li>\n</ul>\n<h3 id=\"skipper-server\" style=\"position:relative;\"><a href=\"#skipper-server\" aria-label=\"skipper server permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Skipper Server</h3>\n<p>The Skipper Server is responsible for:</p>\n<ul>\n<li>Deploying Streams to one or more platforms.</li>\n<li>Upgrading and rolling back Stream on one or more platforms by using a State Machine based blue/green update strategy.</li>\n<li>Storing the history of each Stream's manifest file (which represents the final description of what applications have been deployed).</li>\n</ul>\n<h3 id=\"database\" style=\"position:relative;\"><a href=\"#database\" aria-label=\"database permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Database</h3>\n<p>The Data Flow Server and Skipper Server need to have an RDBMS installed.\nBy default, the servers use an embedded H2 database.\nYou can configure the servers to use external databases.\nThe supported databases are H2, HSQLDB, MySQL, Oracle, Postgresql, DB2, and SqlServer.\nThe schemas are automatically created when each server starts.</p>\n<h3 id=\"security\" style=\"position:relative;\"><a href=\"#security\" aria-label=\"security permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Security</h3>\n<p>The Data Flow and Skipper Server executable jars use OAuth 2.0 authentication to secure the relevant REST endpoints.\nThese can be accessed by using either basic authentication or by using OAuth2 access tokens.\nFor an OAuth provider, we recommend the CloudFoundry User Account and Authentication (UAA) Server, which also provides comprehensive LDAP support. See the <a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/2.6.0.BUILD-SNAPSHOT/reference/htmlsingle/#configuration-local-security\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Security Section</a> in the reference guide for more information on configuring security features to your needs.</p>\n<div class=\"custom-block admonition note\"><div class=\"custom-block-body\"><p>By default, the REST endpoints (administration, management, and health) as well as the Dashboard UI do not require authenticated access.</p></div></div>\n<h2 id=\"application-types\" style=\"position:relative;\"><a href=\"#application-types\" aria-label=\"application types permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Application Types</h2>\n<p>Applications come in two flavors:</p>\n<ul>\n<li>\n<p>Long-lived applications. There are two types of long-lived applications.</p>\n<ul>\n<li>Message-driven applications where an unbounded amount of data is consumed or produced through a single input or output (or both).</li>\n<li>The second is a message-driven application that can have multiple inputs and outputs. It could also be an application that does not use messaging middleware at all.</li>\n</ul>\n</li>\n<li>\n<p>Short-lived applications that process a finite set of data and then terminate.\nThere are two variations of short-lived applications.</p>\n<ul>\n<li>The first is a Task that runs your code and records the status of the execution in the Data Flow database.\nIt can, optionally, use the Spring Cloud Task framework and need not be a Java application.\nHowever, the application does need to record its run status in Data Flow's database.</li>\n<li>The second is an extension of the first that includes the Spring Batch framework as the foundation of performing batch processing.</li>\n</ul>\n</li>\n</ul>\n<p>It is common to write long-lived applications based on the Spring Cloud Stream framework and short-lived applications based on the Spring Cloud Task or Spring Batch frameworks.\nThere are many guides in the documentation that show you how to use these frameworks in developing data pipelines.\nHowever, you can also write long-lived and short-lived applications that do not use Spring.\nThey can also be written in other programming languages.</p>\n<p>Depending on the runtime, you can package applications in two ways:</p>\n<ul>\n<li>A Spring Boot uber-jar that is can be accessed from a Maven repository, from a file location, or over HTTP.</li>\n<li>A Docker image hosted in a Docker registry.</li>\n</ul>\n<h3 id=\"long-lived-applications\" style=\"position:relative;\"><a href=\"#long-lived-applications\" aria-label=\"long lived applications permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Long-lived Applications</h3>\n<p>Long-lived applications are expected to run continuously.\nIf the application stops, the platform is responsible for restarting it.</p>\n<p>The Spring Cloud Stream framework provides a programming model to simplify the writing of message-driven microservice applications that are connected to a common messaging system.\nYou can write core business logic that is agnostic to the specific middleware.\nThe middleware to use is determined by adding a Spring Cloud Stream Binder library as a dependency to the application.\nThere are binding libraries for the following messaging middleware products:</p>\n<ul>\n<li><a href=\"https://www.rabbitmq.com\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">RabbitMQ</a></li>\n<li><a href=\"https://kafka.apache.org\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kafka</a></li>\n<li><a href=\"https://kafka.apache.org/documentation/streams/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kafka Streams</a></li>\n<li><a href=\"https://aws.amazon.com/kinesis/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Amazon Kinesis</a></li>\n<li><a href=\"https://cloud.google.com/pubsub/docs/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Google Pub/Sub</a></li>\n<li><a href=\"https://solace.com/software/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Solace PubSub+</a></li>\n<li><a href=\"https://azure.microsoft.com/en-us/services/event-hubs/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Azure Event Hubs</a></li>\n</ul>\n<div class=\"custom-block admonition note\"><div class=\"custom-block-body\"><p>The Data Flow server delegates to the Skipper server to deploy long-lived applications.</p></div></div>\n<h4 id=\"streams-with-sources-processors-and-sinks\" style=\"position:relative;\"><a href=\"#streams-with-sources-processors-and-sinks\" aria-label=\"streams with sources processors and sinks permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Streams with Sources, Processors and Sinks</h4>\n<p>Spring Cloud Stream defines the concept of a binding interface that encapsulates in code a message exchange pattern, namely what the applications inputs and outputs are.\nSpring Cloud Stream provides several binding interfaces that correspond to the following common message exchange contracts:</p>\n<ul>\n<li><code class=\"language-text\">Source</code>: Message producer that sends messages to a destination.</li>\n<li><code class=\"language-text\">Sink</code>: Message consumer that reads messages from a destination.</li>\n<li><code class=\"language-text\">Processor</code>: The combination of a source and a sink. A processor consumes message from a destination and produces messages to send to another destination.</li>\n</ul>\n<p>Applications of these three types are registered with Data Flow by using the <code class=\"language-text\">source</code>, <code class=\"language-text\">processor</code> and <code class=\"language-text\">sink</code> to describe the <code class=\"language-text\">type</code> of the application being registered.</p>\n<p>The following example shows the shell syntax for registration of a <code class=\"language-text\">http</code> source (an application that listens for HTTP requests and sends HTTP payload to a destination) and a <code class=\"language-text\">log</code> sink (an application that consumes from a destination and logs the received message):</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">dataflow:>app register --name http --type source --uri maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE\nSuccessfully registered application 'source:http'\n\ndataflow:>app register --name log --type sink --uri maven://org.springframework.cloud.stream.app:log-sink-rabbit:1.1.0.RELEASE\nSuccessfully registered application 'sink:log'</code></pre></div>\n      </div>\n<p>With <code class=\"language-text\">http</code> and <code class=\"language-text\">log</code> registered with Data Flow, a stream definition can be created by using the Stream Pipeline DSL, which uses a pipes and filters syntax, as the following example shows:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">dataflow:>stream create --name httpStream --definition \"http | log\"</code></pre></div>\n      </div>\n<p>The pipe symbol in <code class=\"language-text\">http | log</code> represents the connection of the source output to the sink input.\nData Flow sets the appropriate properties when deploying the stream so that the <code class=\"language-text\">source</code> can communicate with the <code class=\"language-text\">sink</code> over the messaging middleware.</p>\n<h4 id=\"streams-with-multiple-inputs-and-outputs\" style=\"position:relative;\"><a href=\"#streams-with-multiple-inputs-and-outputs\" aria-label=\"streams with multiple inputs and outputs permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Streams with Multiple Inputs and Outputs</h4>\n<p>Sources, Sink, and Processors all have a single output, a single input, or both.\nThis is what makes it possible for Data Flow to set application properties that pair an output destination to an input destination.\nHowever, a message processing application could have more than one input or output destination.\nSpring Cloud Stream supports this by letting you define a custom binding interface.</p>\n<p>To define a stream that contains an application with multiple inputs, you must register the application by using the <code class=\"language-text\">app</code> type instead of the <code class=\"language-text\">source</code>, <code class=\"language-text\">sink</code>, or <code class=\"language-text\">processor</code> types.\nThe stream definition uses the Stream Application DSL, which replaces the single pipe symbol (<code class=\"language-text\">|</code>) with the double pipe symbol (<code class=\"language-text\">||</code>).\nThink of <code class=\"language-text\">||</code> as meaning 'in parallel', with no implied connection between the applications.</p>\n<p>The following example shows a fictional 'orderStream':</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">dataflow:> stream create --definition \"orderGeneratorApp || baristaApp || hotDrinkDeliveryApp || coldDrinkDeliveryApp\" --name orderStream</code></pre></div>\n      </div>\n<p>When you define a Stream by using the <code class=\"language-text\">|</code> symbol, Data Flow can configure each application in the stream to communicate with its neighboring application in the DSL, since there is always one output paired to one input.\nWhen you use the <code class=\"language-text\">||</code> symbol, you must provide configuration properties that pair together the multiple output and input destinations.</p>\n<div class=\"custom-block admonition note\"><div class=\"custom-block-body\"><p>You can also create a stream with a single application by using the Stream Application DSL as well as deploying an application that does not use messaging middleware.</p></div></div>\n<p>These examples give you a general sense of the long-lived application types.\nAdditional guides go into more detail on how to develop, test, and register long-lived applications and how to deploy them.</p>\n<p>The next major section discusses the runtime architecture of the deployed stream.</p>\n<!-- **TODO This should be a link. I'd add it, but I can't figure out the order of this documentation, given that this file doesn't seem to be linked into the documentation. ** -->\n<h3 id=\"short-lived-applications\" style=\"position:relative;\"><a href=\"#short-lived-applications\" aria-label=\"short lived applications permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Short-lived Applications</h3>\n<p>Short-lived applications run for a period of time (often minutes to hours) and then terminate.\nTheir runs may be based on a schedule (for example, execute at 6pm every weekday) or in response to an event (for example, a file being put in an FTP server).</p>\n<p>The Spring Cloud Task framework lets you develop a short-lived microservice that records the life cycle events (such as the start time, end time and the exit code) of a short lived application.</p>\n<p>A task application is registered with Data Flow using the name <code class=\"language-text\">task</code> to describe the type of application.</p>\n<p>The following example shows the shell syntax for registering a <code class=\"language-text\">timestamp</code> task (an application that prints the current time and exits):</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">dataflow:> app register --name timestamp --type task --uri maven://org.springframework.cloud.task.app:timestamp-task:2.1.0.RELEASE</code></pre></div>\n      </div>\n<p>The task definition is created by referencing the name of the task, as the following example shows:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">dataflow:> task create tsTask --definition \"timestamp\"</code></pre></div>\n      </div>\n<p>The Spring Batch framework is probably what comes to mind for Spring developers who write short-lived applications.\nSpring Batch provides a much richer set of functionality than Spring Cloud Task and is recommended when processing large volumes of data.\nA use case might be to read many CSV files, transform each row of data, and write each transformed row to a database.\nSpring Batch provides its own database schema with a much more rich set of information about the execution of a Spring Batch job.\nSpring Cloud Task is integrated with Spring Batch so that, if a Spring Cloud Task application defined a Spring Batch Job, a link between the Spring Cloud Task and Spring Cloud Batch run tables is created.</p>\n<p>Tasks that use Spring Batch are registered and created in the same way as shown previously.</p>\n<div class=\"custom-block admonition note\"><div class=\"custom-block-body\"><p>The Spring Cloud Data Flow server launches the task to the platform.</p></div></div>\n<h4 id=\"composed-tasks\" style=\"position:relative;\"><a href=\"#composed-tasks\" aria-label=\"composed tasks permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Composed Tasks</h4>\n<p>Spring Cloud Data Flow lets a user create a directed graph, where each node of the graph is a task application.</p>\n<p>This is done by using the Composed Task Domain Specific Language for composed tasks.\nThere are several symbols in the Composed Task DSL that determine the overall flow.\nThe <a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/2.6.0.BUILD-SNAPSHOT/reference/htmlsingle/##_composed_tasks_dsl\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">reference guide</a> goes into detail. The following example shows how the double ampersand symbol (<code class=\"language-text\">&amp;&amp;</code>) is used for conditional execution:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">dataflow:> task create simpleComposedTask --definition \"task1 &amp;&amp; task2\"</code></pre></div>\n      </div>\n<p>The DSL expression (<code class=\"language-text\">task1 &amp;&amp; task2</code>) means that <code class=\"language-text\">task2</code> is launched only if <code class=\"language-text\">task1</code> has executed successfully.\nThe graph of tasks are run through a task application called the <em>Composed Task Runner</em>.</p>\n<p>Additional guides will go into more detail on how to develop, test, and register short-lived applications and how to deploy them.</p>\n<h3 id=\"application-metadata\" style=\"position:relative;\"><a href=\"#application-metadata\" aria-label=\"application metadata permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Application Metadata</h3>\n<p>The long-lived and the short-lived applications can provide metadata about the supported configuration properties. The metadata is used by Shell and UI tools to offer contextual help and code completion when building data pipelines. It is packaged together with the application or provided as an additional artifact.</p>\n<p>The application <a href=\"https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-external-config\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">configuration properties</a> details are captured as Spring Boot <a href=\"https://docs.spring.io/spring-boot/docs/current/reference/html/appendix-configuration-metadata.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Configuration Metadata</a> and the <code class=\"language-text\">whitelist properties</code> are used to specify from all the metadata, only the primary properties, essential for application's operation.</p>\n<p>Depending on the runtime, the metadata is packaged in two ways:</p>\n<ul>\n<li>For the uber-jar packaged applications an additional metadata-jar is provided, to accommodate the <code class=\"language-text\">configuration metadata</code> and the <code class=\"language-text\">whitelist properties</code> for that application.</li>\n<li>For the Docker image packaged applications, the whitelisted properties are extracted from the configuration metadata and provided as a Docker image configuration label.</li>\n</ul>\n<p>Find more about how to generate and use <a href=\"/docs/1.0.x/feature-guides/general/application-metadata/\">Application Metadata</a> in the related features guide.</p>\n<h2 id=\"prebuilt-applications\" style=\"position:relative;\"><a href=\"#prebuilt-applications\" aria-label=\"prebuilt applications permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Prebuilt Applications</h2>\n<p>To kick start your development, you can use many pre-built applications to integrate with common data sources and sinks.\nFor example, you can use a <code class=\"language-text\">cassandra</code> sink that writes data to Cassandra and a <code class=\"language-text\">groovy-transform</code> processor that transforms the incoming data by using a Groovy script.</p>\n<p>The installation instructions show how to register these applications with Spring Cloud Data Flow.</p>\n<p>You can find more information on pre-built applications in the <a href=\"/docs/1.0.x/concepts/\">concepts guide</a>.</p>\n<h2 id=\"microservice-architectural-style\" style=\"position:relative;\"><a href=\"#microservice-architectural-style\" aria-label=\"microservice architectural style permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Microservice Architectural Style</h2>\n<p>The Data Flow and Skipper servers deploy Streams and Composed Batch Jobs to the platform as a collection of microservice applications, each running in their own process.\nEach microservice application can be scaled up or down independently of the other, and each has its own versioning lifecycle.\nSkippers lets you independently upgrade or roll back each application in a stream at runtime.</p>\n<p>When using Spring Cloud Stream and Spring Cloud Task, each microservice application builds upon Spring Boot as the foundational library.\nThis gives all microservice applications functionality, such as health checks, security, configurable logging, monitoring, and management functionality, as well as executable JAR packaging.</p>\n<p>It is important to emphasize that these microservice applications are \"just apps\" that you can run for yourself by using <code class=\"language-text\">java -jar</code> and passing in appropriate configuration properties.\nCreating your own microservice application for data processing is similar to creating other Spring Boot applications. You can start by using the Spring Initializr web site to create the basic scaffolding of either a Stream-based or a Task-based microservice.</p>\n<p>In addition to passing the appropriate application properties to each applications, the Data Flow and Skipper servers are responsible for preparing the target platform’s infrastructure.\nFor example, in Cloud Foundry, it would bind specified services to the applications. For Kubernetes, it would create the deployment and service resources.</p>\n<p>The Data Flow Server helps simplify the deployment of multiple related applications onto a target runtime, setting up necessary input and output topics, partitions, and metrics functionality.\nHowever, you can also opt to deploy each of the microservice applications manually and not use Data Flow or Skipper at all.\nThis approach might be more appropriate to start out with for small scale deployments, gradually adopting the convenience and consistency of Data Flow as you develop more applications.\nManual deployment of Stream and Task-based microservices is also a useful educational exercise that can help you better understand some of the automatic application configuration and platform targeting steps that the Data Flow Server provides.\nThe Stream and Batch developer guides follow this approach.</p>\n<h4 id=\"comparison-to-other-architectures\" style=\"position:relative;\"><a href=\"#comparison-to-other-architectures\" aria-label=\"comparison to other architectures permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Comparison to Other Architectures</h4>\n<p>Spring Cloud Data Flow’s architectural style is different than other Stream and Batch processing platforms.\nFor example in Apache Spark, Apache Flink, and Google Cloud Dataflow, applications run on a dedicated compute engine cluster.\nThe nature of the compute engine gives these platforms a richer environment for performing complex calculations on the data as compared to Spring Cloud Data Flow, but it introduces the complexity of another execution environment that is often not needed when creating data-centric applications.\nThat does not mean that you cannot do real-time data computations when you use Spring Cloud Data Flow.\nFor example, you can develop applications that use the Kafka Streams API that time-sliding-window and moving-average functionality as well as joins of the incoming messages against sets of reference data.</p>\n<p>A benefit of this approach is that we can delegate to popular platforms as the execution runtime.\nData Flow can benefit from their feature set (resilience, scalability) as well as the knowledge you may already have about those platforms as you maybe using them for other purposes.\nThis reduces the cognitive distance for creating and managing data-centric applications as many of the same skills used for deploying other end-user/web applications are applicable.</p>\n<h3 id=\"streams\" style=\"position:relative;\"><a href=\"#streams\" aria-label=\"streams permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Streams</h3>\n<p>The following image shows the runtime architecture of a simple stream:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 698px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 74%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAAsTAAALEwEAmpwYAAACQUlEQVQ4y31UyW7bQAz1/6NAP6Lof/RQFGgPPbQJYsuKZFuLNdrX0TbyK8lYrREbZUBrFvKRfORkc7lcMI4jhmEQnaYJfMa6LIvoun+kLOuXZcMOVVVBKSXatq0YmNmgo3Wve/xPbsEEcD0YKMueMnyzArpxQKFblLqT72QMhnmSdTVoOef9XYb80ww9/CSCRzqSI8u5SLHd77C397CPDmoCybsG7snF08szvNBH0pT3gIY2YZ7gdHARBB4BZdBaw4vPCMMAr84OQRQgqQoKqpCoiILsoOg+bap7QN4wiHNw4HoHMVooS5XnsM6/8OnpA578n6i7HnFZ4KgsfH7+iN/+D5St/gu4qpSspxFZW4vO15LDIsdLsMP34zdsAxtVr6nEitYWvjpf6G6LuK4ec/ioc/NiYJY3w5lHh/4WOV/QNQP4yvD5dbTW8drM8yyzdzuDqxi6i2OFPMuQJinyNENBVCjiMU1T1DRu7M/K/oaq28RxDNu24bouLMtCFEXIyYkbwwZsmFGpqsyREyWcyXQFMVd6pApaC2BRENHHI5Ikkaj8ZdC+77l2NMSdLx334adKZq8ZBymfZSJqFqnmCsiR2PnRM2J+yq7F6ezj8LqHr85IqFkOjQ/Pa0lDzplHpJqCsP3mfTNWgoVDcprNjJRKjetCBpt5tSnjIInhqRAHx0YQegIqTXn/0FlWUG4SV3BZO321GykId1gehH+CF4Uo2ubfHN6Wewu80sH/jW51GinQNKOh98wviJumyY4fxB/tiYdR4pFXaAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/f13ee613fce12fbfb3bb72ecfcb34508/507e6/arch-stream-dsl.webp 200w,\n/static/f13ee613fce12fbfb3bb72ecfcb34508/28a80/arch-stream-dsl.webp 400w,\n/static/f13ee613fce12fbfb3bb72ecfcb34508/40323/arch-stream-dsl.webp 698w\"\n              sizes=\"(max-width: 698px) 100vw, 698px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/f13ee613fce12fbfb3bb72ecfcb34508/36ca5/arch-stream-dsl.png 200w,\n/static/f13ee613fce12fbfb3bb72ecfcb34508/a3397/arch-stream-dsl.png 400w,\n/static/f13ee613fce12fbfb3bb72ecfcb34508/a4922/arch-stream-dsl.png 698w\"\n            sizes=\"(max-width: 698px) 100vw, 698px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/f13ee613fce12fbfb3bb72ecfcb34508/a4922/arch-stream-dsl.png\"\n            alt=\"Stream Architecture with Sources, Processor, and Sinks\"\n            title=\"Stream Architecture with Sources, Processor, and Sinks\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n    </span></p>\n<p>The Stream DSL is sent by <code class=\"language-text\">POST</code> to the Data Flow Server. Based on the mapping of DSL application names to Maven and Docker artifacts, the <code class=\"language-text\">http</code> source and <code class=\"language-text\">jdbc</code> sink applications are deployed by Skipper to the target platform.\nData that is posted to the HTTP application is then stored in a database.</p>\n<div class=\"custom-block admonition note\"><div class=\"custom-block-body\"><p>The <code class=\"language-text\">http</code> source and <code class=\"language-text\">jdbc</code> sink applications are running on the specified platform and have no connection to the Data Flow or Skipper server.</p></div></div>\n<p>The runtime architecture of a stream consisting of applications that can have multiple inputs and outputs is shown below.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 697px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 79.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsTAAALEwEAmpwYAAACkklEQVQ4y21U2W7bMBD0/wNFf6L9lDw0RZu2SIHEka3DsiyJug/KOqeztGXkKI0VRYqcnd2d9WZZFsiY5xl936NtW2N1XcP3fXieh8PhgDAMzbtt2wijyJxpmgbTNBmTu4K1WQGHYTAgWmukaYo0SZEoZUzFMbIsQ0wgFV/2cq4znluJCPgbwHEc0Z/PWMdZ1vOEgdaNAxb+pmXGeRoxcpa9gczej4082qHHMY3hxidzUIYdBfj5+BsPtCd3B839pKnwtH/B/cMPWJ6NqCrMWSG12kb4RWUGy9rCcfYIixSaTIMkQngKEPgeTipE0TYIswRJHMFzbSgVIanLN4A3hnGZwzk4cHwXUZFBdx2OvPjLv8OXx0/YhzsUTUsnCl78gq9/P+PP4Rv39EeGstEzL3lbG1vzEpDNNngi6Hd4KmDuJmRkaUc27t07WKFFhtV/Qr5SfT8GJr6fZsx8r8m4qipUTY2kKFDW2nyb5vkGeCuKLKTkIhWRRp7nKOQSrSZIWZbQ1JzISfQ200YWqNYtSjLuKBmjkOEyb0RHclhAO86d7m5rbdZaKBjvPS/MZF4SzA2P8E4+1LXSsi9a3ojXhaB8ounPRkKvR8f8xjlFXBaIixyK8zGJjSKs7TNOeWL0KZEaQGE40LN8sJwd9kePxWnIZjBMZL3j/oEymq9MxWlA0IDSKXRza10DKOw0mRnAl2e4lE+QKUqJTFIFl4D23jK6lM6RIYxUUyKqC3bU8DFkSbR48tgpPjumv0pHqhhS9M7paMJspBC0KE+xZ6ds2QzSCMu10reQpTrvx2sxmTxTJnWnkdOxNIJ7cPnPszONsFy08yqHfBFQmYfx8r6arAVwvEbC2IxUJBKfaSjpQPZXjH8+As7uiyT+IwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/890208507e915e3e3c789cd47210c2b3/507e6/arch-app-dsl.webp 200w,\n/static/890208507e915e3e3c789cd47210c2b3/28a80/arch-app-dsl.webp 400w,\n/static/890208507e915e3e3c789cd47210c2b3/9fe93/arch-app-dsl.webp 697w\"\n              sizes=\"(max-width: 697px) 100vw, 697px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/890208507e915e3e3c789cd47210c2b3/36ca5/arch-app-dsl.png 200w,\n/static/890208507e915e3e3c789cd47210c2b3/a3397/arch-app-dsl.png 400w,\n/static/890208507e915e3e3c789cd47210c2b3/efc0f/arch-app-dsl.png 697w\"\n            sizes=\"(max-width: 697px) 100vw, 697px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/890208507e915e3e3c789cd47210c2b3/efc0f/arch-app-dsl.png\"\n            alt=\"Stream Architecture with multiple inputs and outputs\"\n            title=\"Stream Architecture with multiple inputs and outputs\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n    </span></p>\n<p>Architecturally, it is the same as when using <code class=\"language-text\">Source</code>, <code class=\"language-text\">Sink</code> or <code class=\"language-text\">Processor</code> applications.\nThe Stream Application DSL to define this architecture uses the double pipe symbol (<code class=\"language-text\">||</code>) instead of the single pipe (<code class=\"language-text\">|</code>) symbol.\nAlso, when you deploy this stream, you must provide more information that describes how to connect each application to another by using the messaging system.</p>\n<h3 id=\"tasks-and-batch-jobs\" style=\"position:relative;\"><a href=\"#tasks-and-batch-jobs\" aria-label=\"tasks and batch jobs permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Tasks and Batch Jobs</h3>\n<p>The following image shows the runtime architecture for a Task and a Spring Batch Job:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 609px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 97.00000000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAAAsTAAALEwEAmpwYAAACV0lEQVQ4y41UW47aQBDkdDlZDpET5ApRvqJEuUCUrBCLAYPH77WN8Qs/cKVrwljAQnZHatkM3TXV1TWejeMIxlvL5B2PRzRNg7qu9fttzuy24DK4TqeTjr7vMQyDBmJUVaWB+R/3Tf6MG/wjSRKEYYg4jhEEAdI0heu6OBwOyLJM/97v9xqIT+6xhiwZBNWAXddNJzLJFB+KQhdwv21bXcTnZXCP9a8AyfBda7wvjWlXa6hPEMBBfpTtUQdX07VY+g5WroO158DyFWrZe2vNDGU/T+GEHuzARVYVutjabTB/+oP18wJrx0ZaHtBUtZajkKAcfLL9aSijDMUJfKjIx2b5DLWzoV5CqDCAFwew1BY/F0/YyEHBS4xQBuZ5Hnzf10NUSmngK9uw3Z2A2MKCTMI8Q9HU2EjLH79/wYfPn/Bt8Rtt371qkexoqQnQUK1Eu6wukUi7Jxp46GGFLn5Yc3yd/8KTsvUhppB201qL/pTtiuHtTWHCPs8RZSkyedYCVAu7YTzhMp/6sXV6l3b7p+HFyM07h8SE5uxPc8XoNTIzeTQ9NaSm9KwGvL2L5rqRZS7seGsCGRoPoF7cN3llWWqGDOY+BCQTakMwa7XCar3WRWTKAVweTCACTzflHmDP1iQ4IFu8uZWIinya6q08V1O+B0hvcqJKfOiqHZSz1aYvjs3ExKx3AYpvkAijIIngbG1sVkvEaSwHhAjOho6iSAffOe3ppjzSkG0rAbHlHm8laPxemPPTtT/rRiBOml+r/wKyhVZaqSXyqtRRigSD7Hfn9h591f8CI7rBVzQ+6J0AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/a79a39a83bdff7dc306bb29663b1c22b/507e6/arch-batch-dsl.webp 200w,\n/static/a79a39a83bdff7dc306bb29663b1c22b/28a80/arch-batch-dsl.webp 400w,\n/static/a79a39a83bdff7dc306bb29663b1c22b/4f6f5/arch-batch-dsl.webp 609w\"\n              sizes=\"(max-width: 609px) 100vw, 609px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/a79a39a83bdff7dc306bb29663b1c22b/36ca5/arch-batch-dsl.png 200w,\n/static/a79a39a83bdff7dc306bb29663b1c22b/a3397/arch-batch-dsl.png 400w,\n/static/a79a39a83bdff7dc306bb29663b1c22b/b7bac/arch-batch-dsl.png 609w\"\n            sizes=\"(max-width: 609px) 100vw, 609px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/a79a39a83bdff7dc306bb29663b1c22b/b7bac/arch-batch-dsl.png\"\n            alt=\"Task Runtime architecture for Tasks and Spring Batch Jobs\"\n            title=\"Task Runtime architecture for Tasks and Spring Batch Jobs\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n    </span></p>\n<h3 id=\"composed-tasks-1\" style=\"position:relative;\"><a href=\"#composed-tasks-1\" aria-label=\"composed tasks 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Composed Tasks</h3>\n<p>The following image shows the runtime architecture for a composed task:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 702px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 67%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAABvklEQVQ4y51T246bMBDN/39E/6H9gb5W6lP7lt1lAXNZAgkEbAwGw+mMNw4ovUhbSyPLDD6XmfEBH1jrurrgdblcIIRAlmVI0xTjOGKaJhystTDGuIMPPs/z7C73fQ9FsWID48Xfu66jnIJSCozjAPlyURT3KKvSsUop31UtBLQsvyllQl6VbKG13gD3NrQeNhV8abFoRw1pBrRDDz0Zl1qIgAEVfRenN5wJlBeLO3jWppdIq9M96Qhmg2MU4Ph8xEsYIG/OW86MiE85sjxBlAnIcYAlEgfIzPFbioguJUWGRnaYRoOqqZHSOQ5fqQwJ8kvpiq+kQkt1iykn4hBhEqPbAw7z5JIvwTME7YqSbPmqSHWZ4svTJ3wNPuN8bZ1dc2teO2iE9H/R1k71xJZ9zbhGNdm+6v5uS5GtpzzCd/ENP5MfZLn2bXGAVXdFXhXI6wp2Xd6b4rv22MV7N6l7dB/caOu7TWdJ6iKqXxK9IqA6N1ptltfd0O7BdhS32P5l26ysKAskpHKiiZi9wj+9CDyQPJLx2FiCFzQZXGtXw78B/uvp+Z1njhvEY6bJvn9lh/99y/wyWOVCu70FE/wCBonzjFs3DwgAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/63721a3db92448c8c6ad44a9edfcb9b9/507e6/arch-composed-task-dsl.webp 200w,\n/static/63721a3db92448c8c6ad44a9edfcb9b9/28a80/arch-composed-task-dsl.webp 400w,\n/static/63721a3db92448c8c6ad44a9edfcb9b9/1c613/arch-composed-task-dsl.webp 702w\"\n              sizes=\"(max-width: 702px) 100vw, 702px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/63721a3db92448c8c6ad44a9edfcb9b9/36ca5/arch-composed-task-dsl.png 200w,\n/static/63721a3db92448c8c6ad44a9edfcb9b9/a3397/arch-composed-task-dsl.png 400w,\n/static/63721a3db92448c8c6ad44a9edfcb9b9/d0434/arch-composed-task-dsl.png 702w\"\n            sizes=\"(max-width: 702px) 100vw, 702px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/63721a3db92448c8c6ad44a9edfcb9b9/d0434/arch-composed-task-dsl.png\"\n            alt=\"Composed Task Runtime architecture for Tasks and spring Batch Jobs\"\n            title=\"Composed Task Runtime architecture for Tasks and spring Batch Jobs\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n    </span></p>\n<h2 id=\"platforms\" style=\"position:relative;\"><a href=\"#platforms\" aria-label=\"platforms permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Platforms</h2>\n<p>You can deploy the Spring Cloud Data Flow Server and the Skipper Server on Cloud Foundry, Kubernetes, and your local Machine.</p>\n<p>You can also deploy the applications that are deployed by these servers to multiple platforms:</p>\n<ul>\n<li>Local: Can deploy to the local machine, Cloud Foundry, or Kubernetes.</li>\n<li>Cloud Foundry: Can deploy to Cloud Foundry or Kubernetes.</li>\n<li>Kubernetes: Can deploy to Kubernetes or Cloud Foundry.</li>\n</ul>\n<p>The most common architecture is to install the Data Flow and Skipper server on the same platform where you deploy your applications.\nYou can also deploy to multiple Cloud Foundry org, space, and foundations and multiple Kubernetes Clusters.</p>\n<p>There are community implementations that let you deploy to other platforms, namely <a href=\"https://github.com/donovanmuller/spring-cloud-dataflow-server-nomad\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HashiCorp Nomad</a>, <a href=\"https://github.com/donovanmuller/spring-cloud-dataflow-server-openshift\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Red Hat OpenShift</a>, and <a href=\"https://github.com/trustedchoice/spring-cloud-dataflow-server-mesos\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Apache Mesos</a>.</p>\n<div class=\"admonition important\"><p>The local server is supported in production for Task deployment as a replacement for the Spring Batch Admin project. The local server is not supported in production for Stream deployments.</p></div>","headings":[{"value":"Architecture","depth":1},{"value":"Server Components","depth":2},{"value":"Data Flow Server","depth":3},{"value":"Skipper Server","depth":3},{"value":"Database","depth":3},{"value":"Security","depth":3},{"value":"Application Types","depth":2},{"value":"Long-lived Applications","depth":3},{"value":"Streams with Sources, Processors and Sinks","depth":4},{"value":"Streams with Multiple Inputs and Outputs","depth":4},{"value":"Short-lived Applications","depth":3},{"value":"Composed Tasks","depth":4},{"value":"Application Metadata","depth":3},{"value":"Prebuilt Applications","depth":2},{"value":"Microservice Architectural Style","depth":2},{"value":"Comparison to Other Architectures","depth":4},{"value":"Streams","depth":3},{"value":"Tasks and Batch Jobs","depth":3},{"value":"Composed Tasks","depth":3},{"value":"Platforms","depth":2}],"fields":{"path":"/docs/1.0.x/concepts/architecture/","version":"1.0.x","category":"concepts","sourcePath":"pages/2-concepts/1-architecture.md"},"frontmatter":{"title":"Architecture","summary":null,"path":"concepts/architecture/","toc":null,"prevNext":null}}},"pageContext":{"slug":"/docs/1.0.x/concepts/architecture/","version":"1.0.x","versionPath":""}},"staticQueryHashes":["1084522749","2044043181"]}