{"componentChunkName":"component---src-templates-documentation-js","path":"/docs/sql-developer-guides/getting-started/sql/","result":{"data":{"pages":{"edges":[{"node":{"id":"3ecc7a35-a4a0-50f5-8ca3-075cb1a85294","fields":{"path":"/docs/installation/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Installation","description":"How to install anyscale","path":"installation/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f1c53ccb-0064-51d7-9b7f-54c6ed432f18","fields":{"path":"/docs/installation/local/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Local Machine","description":"Local Machine Installation Guide","path":"installation/local/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6b228ad2-818d-5a06-901a-9521fe71a005","fields":{"path":"/docs/installation/local/single-node/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Single Node","description":"Installation using Single Node","path":"installation/local/single-node","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a29b5f60-603c-5a7d-a603-cb9ecb42ffdf","fields":{"path":"/docs/installation/local/multi-node/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Multi Node","description":"Installation using Multi Node","path":"installation/local/multi-node","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"96b33d1e-fb27-5955-9776-3f9b77560759","fields":{"path":"/docs/installation/local/manual/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Manual","description":"Manual installation","path":"installation/local/manual","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3b872bda-042a-53b9-ab03-5f7848a87255","fields":{"path":"/docs/installation/cloud/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Cloud","description":"Anyscale Stack Cloud Installation Guide","path":"installation/cloud/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ba9614fa-3aff-5dd8-b878-c52a1964543f","fields":{"path":"/docs/installation/cloud/cf-cli/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Cloud CLI","description":"Install using the Cloud CLI","path":"installation/cloud/cf-cli","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8d0bc514-d33a-56ed-9971-14a938514a19","fields":{"path":"/docs/installation/cloud/cf-local/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Running locally","description":"Configure the local servers to deploy to Cloud","path":"installation/cloud/cf-local","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e193dae4-0551-5e09-8b67-c69700058ecc","fields":{"path":"/docs/installation/kubernetes/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Kubernetes","description":"Data Flow Kubernetes Installation Guide","path":"installation/kubernetes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"71fabca3-63cd-5032-8d07-d4f066daeb11","fields":{"path":"/docs/installation/kubernetes/creating-a-cluster/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Creating a Cluster","description":"Creating a Kubernetes Cluster","path":"installation/kubernetes/creating-a-cluster","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0b8a6e6c-ddc2-5ad9-8ebc-dd0e342c440f","fields":{"path":"/docs/installation/kubernetes/helm/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Helm","description":"Installation using Helm","path":"installation/kubernetes/helm","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"591ecf46-8124-5175-b61c-5f0265ac12e9","fields":{"path":"/docs/installation/kubernetes/kubectl/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"kubectl","description":"Installation using kubectl","path":"installation/kubernetes/kubectl","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4ce9650d-67dd-50c9-8e50-2e704698a547","fields":{"path":"/docs/installation/kubernetes/compatibility/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Kubernetes Compatibility","description":"Compatibility with Kubernetes Versions","path":"installation/kubernetes/compatibility","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2c6cc459-6e7a-5ded-b630-f243a9b9f1ff","fields":{"path":"/docs/design/","version":"1.1.0.SNAPSHOT","category":"design"},"frontmatter":{"title":"Design","description":"FusionDB design guides","path":"design/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"25779935-8431-5dfa-9a92-a74d2fc66380","fields":{"path":"/docs/design/concept/","version":"1.1.0.SNAPSHOT","category":"design"},"frontmatter":{"title":"Concept","description":"design of concept","path":"design/concept/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f08eaac6-83c1-59a7-9be1-25f752d46151","fields":{"path":"/docs/design/fql/","version":"1.1.0.SNAPSHOT","category":"design"},"frontmatter":{"title":"SQL Layer","description":"SQL Layer","path":"design/fql/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6c48db2b-fc36-593e-9670-3d1450fcdd3f","fields":{"path":"/docs/design/core/","version":"1.1.0.SNAPSHOT","category":"design"},"frontmatter":{"title":"Core Layer","description":"core layer","path":"design/core/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e478f290-68f6-5615-b8a6-97088d76eec5","fields":{"path":"/docs/design/runtime/","version":"1.1.0.SNAPSHOT","category":"design"},"frontmatter":{"title":"Runtime","description":"runtime","path":"design/runtime/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d2b195f9-0bca-560c-8b5a-dbdc5520e735","fields":{"path":"/docs/design/developer/","version":"1.1.0.SNAPSHOT","category":"design"},"frontmatter":{"title":"Developer","description":"developer","path":"design/developer/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ec04335a-97ce-57c7-995f-9e4d96db6049","fields":{"path":"/docs/sql-developer-guides/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"SQL Developer guides ","description":"Learn how to create Batch data pipelines using prebuilt microservices or create your own","path":"sql-developer-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"429988e7-5aa5-50a3-8cf0-338ba884fa7f","fields":{"path":"/docs/sql-developer-guides/getting-started/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Getting Started","description":"Getting Started with SQL","path":"sql-developer-guides/getting-started/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3d73e2f0-ac02-50de-ba80-41711b3a186c","fields":{"path":"/docs/sql-developer-guides/getting-started/sql/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"SQL Using","description":"快速利用 Docker 安装 FusionDB 单机版，体验 FusionDB 相关功能","path":"sql-developer-guides/getting-started/sql/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"346fd6a4-609d-5ad1-ae8c-a45bced7ce47","fields":{"path":"/docs/sql-developer-guides/getting-started/datasource/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"SQL DataSource","description":"使用 SQL 进行联邦数据查询，多数据源聚合分析","path":"sql-developer-guides/getting-started/datasource/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f33ed054-c323-5eb9-bbd7-85964bf4e09a","fields":{"path":"/docs/sql-developer-guides/sql/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"SQL Development","description":"SQL Developer Guide","path":"sql-developer-guides/sql/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c375337c-f867-53a7-b11a-d240bd310ac3","fields":{"path":"/docs/sql-developer-guides/sql/spring-task/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Simple Task","description":"Create a simple Spring Boot Application using Spring Cloud Task","path":"sql-developer-guides/sql/spring-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ea8201ae-04f1-50ec-9f8a-6a387609dfe0","fields":{"path":"/docs/sql-developer-guides/sql/spring-batch/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Spring Batch Jobs","description":"Create a Spring Batch Job","path":"sql-developer-guides/sql/spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5c9729b3-3021-564f-8eb2-a8321406b98a","fields":{"path":"/docs/sql-developer-guides/sql/data-flow-simple-task/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Register and Launch a Spring Cloud Task application using Data Flow","description":"Register and Launch a Spring Cloud Task application using Data Flow","path":"sql-developer-guides/sql/data-flow-simple-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"49525935-e0f0-562f-813b-2d29105d7467","fields":{"path":"/docs/sql-developer-guides/sql/data-flow-spring-batch/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Register and launch a Spring Batch application using Data Flow","description":"Register and launch a Spring Batch application using Data Flow","path":"sql-developer-guides/sql/data-flow-spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6f865c8f-c501-59bd-bdd3-379176588fa1","fields":{"path":"/docs/sql-developer-guides/sql/data-flow-composed-task/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Create and launch a Composed Task using Data Flow","description":"Create and launch a Composed Task using Data Flow","path":"sql-developer-guides/sql/data-flow-composed-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"cc37c6e1-2257-5e0e-96cc-5cd43a2def6b","fields":{"path":"/docs/sql-developer-guides/sql/data-flow-simple-task-kubernetes/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Deploying a task application on Kubernetes with Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Kubernetes using Spring Cloud Data Flow","path":"sql-developer-guides/sql/data-flow-simple-task-kubernetes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"93b44426-31a6-544a-86b2-35f3ba014ae3","fields":{"path":"/docs/sql-developer-guides/sql/data-flow-simple-task-cloudfoundry/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Deploying a task application on Cloud Foundry using Spring Cloud Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Cloud Foundry using Spring Cloud Data Flow","path":"sql-developer-guides/sql/data-flow-simple-task-cloudfoundry/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3484ded6-4802-5492-a292-6c9e78deb100","fields":{"path":"/docs/sql-developer-guides/continuous-deployment/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Continuous Deployment","description":"Continuous Deployment for task applications","path":"sql-developer-guides/continuous-deployment/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e3efa0fd-52c6-5594-92d8-8b098a0a8642","fields":{"path":"/docs/sql-developer-guides/continuous-deployment/cd-basics/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Continuous Deployment of task applications","description":"This section discusses how to use Continuous Deployment of Tasks in SCDF","path":"sql-developer-guides/continuous-deployment/cd-basics/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e2213760-12ff-5dfc-aba5-ab56971e577f","fields":{"path":"/docs/sql-developer-guides/troubleshooting/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Troubleshooting","description":"Troubleshooting Batch Jobs","path":"sql-developer-guides/troubleshooting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2396db76-6ce6-5fa0-b5ac-102773364cc1","fields":{"path":"/docs/sql-developer-guides/troubleshooting/debugging-task-apps/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Debugging Batch applications","description":"Debugging Batch applications","path":"sql-developer-guides/troubleshooting/debugging-task-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2320f09c-15d7-51cd-9b17-0e8846542fc4","fields":{"path":"/docs/sql-developer-guides/troubleshooting/debugging-scdf-tasks/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Debugging Batch applications deployed by Data Flow","description":"Debugging Batch applications deployed by Data Flow","path":"sql-developer-guides/troubleshooting/debugging-scdf-tasks/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"fea3a6a4-a66e-5cfd-9b37-ca898f5b5190","fields":{"path":"/docs/concepts/","version":"1.1.0.SNAPSHOT","category":"concepts"},"frontmatter":{"title":"Concepts","description":"Core Concepts in Spring Cloud Data Flow","path":"concepts/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"21618e29-2e26-5a55-bf21-b2558a3d03a3","fields":{"path":"/docs/concepts/architecture/","version":"1.1.0.SNAPSHOT","category":"concepts"},"frontmatter":{"title":"Architecture","description":"Introduction to Anyscale Architecture.","path":"concepts/architecture/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"088d6d89-b0c0-5c37-8dcd-2ac0419a071e","fields":{"path":"/docs/concepts/streams/","version":"1.1.0.SNAPSHOT","category":"concepts"},"frontmatter":{"title":"Stream Processing","description":"Stream Processing Framework and Concepts","path":"concepts/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1566bdae-fbc5-58a7-b344-2c78c931d617","fields":{"path":"/docs/concepts/batch-jobs/","version":"1.1.0.SNAPSHOT","category":"concepts"},"frontmatter":{"title":"Batch Processing","description":"Batch Processing Framework and Concepts","path":"concepts/batch-jobs/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a3ba7d4b-fb03-517c-9839-8e8197ed9014","fields":{"path":"/docs/concepts/monitoring/","version":"1.1.0.SNAPSHOT","category":"concepts"},"frontmatter":{"title":"Monitoring","description":"Runtime monitoring of Stream data pipelines","path":"concepts/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"18e13ddd-6f0b-5b14-b11f-679043097e42","fields":{"path":"/docs/concepts/tooling/","version":"1.1.0.SNAPSHOT","category":"concepts"},"frontmatter":{"title":"Tooling","description":"Dashboard and Shell","path":"concepts/tooling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1d5310d0-b1de-5013-9e17-95b19fb87203","fields":{"path":"/docs/concepts/sql/","version":"1.1.0.SNAPSHOT","category":"concepts"},"frontmatter":{"title":"SQL Processing","description":"SQL Processing and Concepts","path":"concepts/sql/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"644a733d-86e6-55b3-bb24-ffd61e3d7118","fields":{"path":"/docs/concepts/roadmap/","version":"1.1.0.SNAPSHOT","category":"concepts"},"frontmatter":{"title":"Roadmap","description":"开发计划","path":"concepts/roadmap/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"fd71c04a-5a0e-5af0-b320-e9358351d3ea","fields":{"path":"/docs/stream-developer-guides/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Developer guides ","description":"Learn how to create Streaming data pipelines using prebuilt microservices or create your own.","path":"stream-developer-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3596d1cf-579d-5ac4-8387-1ea4634fd0e5","fields":{"path":"/docs/stream-developer-guides/getting-started/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Getting Started","description":"Getting Started with Stream Processing","path":"stream-developer-guides/getting-started/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"cf299cf6-53fc-53b1-bd36-62d5d29c6ade","fields":{"path":"/docs/stream-developer-guides/getting-started/stream/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Processing","description":"Create and deploy a streaming data pipeline using prebuilt applications on your Local Machine","path":"stream-developer-guides/getting-started/stream/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c8d2f6d4-17d1-5f54-8757-4466f5d33695","fields":{"path":"/docs/stream-developer-guides/streams/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Development","description":"Stream Processing Developer Guide","path":"stream-developer-guides/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6d2b5081-b96c-5152-8b40-333964ca9825","fields":{"path":"/docs/stream-developer-guides/streams/standalone-stream-rabbitmq/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Application Development on RabbitMQ","description":"Create your own microservices for Stream processing using RabbitMQ and deploy them manually","path":"stream-developer-guides/streams/standalone-stream-rabbitmq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6b69dd51-76d7-5027-a6ee-a6872d1d9049","fields":{"path":"/docs/stream-developer-guides/streams/standalone-stream-kafka/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Application Development on Apache Kafka","description":"Create your own microservices for Stream processing using Apache Kafka and deploy them manually","path":"stream-developer-guides/streams/standalone-stream-kafka/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bffc856f-d9e2-5c65-8bcc-324342396303","fields":{"path":"/docs/stream-developer-guides/streams/data-flow-stream/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Processing using Spring Cloud Data Flow","description":"Create and Deploy a Stream Processing Pipeline using Spring Cloud Data Flow","path":"stream-developer-guides/streams/data-flow-stream/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2dd6ce45-117d-5a25-9367-075e79d52587","fields":{"path":"/docs/stream-developer-guides/streams/stream-other-binders/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Spring Application Development on other Messaging Middleware","description":"Create your own microservices for Stream processing using other messaging middleware such as Google Pub/Sub, Amazon Kinesis, and Solace JMS","path":"stream-developer-guides/streams/stream-other-binders/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9fa08430-1f7b-5dde-a0fc-03817e2a4c37","fields":{"path":"/docs/stream-developer-guides/programming-models/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Programming Models","description":"Programming models","path":"stream-developer-guides/programming-models/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"cc059c39-c9e5-5540-9d08-a588822b7388","fields":{"path":"/docs/stream-developer-guides/continuous-delivery/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Continuous Delivery","description":"CD using Skipper","path":"stream-developer-guides/continuous-delivery/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"dc4df21a-da51-5281-ade7-5440d0d54ea7","fields":{"path":"/docs/stream-developer-guides/continuous-delivery/cd-basics/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Continuous Delivery of streaming applications","description":"Continuous Delivery of Streaming applications","path":"stream-developer-guides/continuous-delivery/cd-basics/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a7cb53c4-542c-52f0-a10b-9c0677f21d5e","fields":{"path":"/docs/stream-developer-guides/troubleshooting/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Troubleshooting","description":"Troubleshooting Streams","path":"stream-developer-guides/troubleshooting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bb657862-05a5-5951-8aa6-edf9434bf3e6","fields":{"path":"/docs/stream-developer-guides/troubleshooting/debugging-stream-apps/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Debugging Stream Applications","description":"Debugging Stream Applications outside of Data Flow","path":"stream-developer-guides/troubleshooting/debugging-stream-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"22c370d7-851f-5413-9a1e-14e785767cf4","fields":{"path":"/docs/stream-developer-guides/troubleshooting/debugging-scdf-streams/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Debugging Stream applications deployed by Data Flow","description":"Debugging Data Flow Stream deployments","path":"stream-developer-guides/troubleshooting/debugging-scdf-streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"82ed2c33-4e67-5756-ad9f-edfbbb4b4ca8","fields":{"path":"/docs/batch-developer-guides/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Batch Developer guides ","description":"Learn how to create Batch data pipelines using prebuilt microservices or create your own","path":"batch-developer-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"369db1c1-0310-5da7-9905-458db85318ee","fields":{"path":"/docs/batch-developer-guides/getting-started/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Getting Started","description":"Getting Started with Batch","path":"batch-developer-guides/getting-started/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f01266d1-bfea-5f1c-bab2-05d7906ba57c","fields":{"path":"/docs/batch-developer-guides/getting-started/task/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Task Processing","description":"Create and deploy a simple Task pipeline using a prebuilt Task application on your local machine","path":"batch-developer-guides/getting-started/task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9e12315c-9a3d-5bac-960c-deecca24953e","fields":{"path":"/docs/batch-developer-guides/batch/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Batch Development","description":"Batch Developer Guide","path":"batch-developer-guides/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2fc4857f-a714-533f-ab6a-060f5fc6e978","fields":{"path":"/docs/batch-developer-guides/batch/spring-task/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Simple Task","description":"Create a simple Spring Boot Application using Spring Cloud Task","path":"batch-developer-guides/batch/spring-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0c71d5bb-707f-58c9-941a-2cb3d73ff346","fields":{"path":"/docs/batch-developer-guides/batch/spring-batch/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Spring Batch Jobs","description":"Create a Spring Batch Job","path":"batch-developer-guides/batch/spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"85dfbeaf-2236-53d0-8c6b-fb08ca9f0ef4","fields":{"path":"/docs/batch-developer-guides/batch/data-flow-simple-task/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Register and Launch a Spring Cloud Task application using Data Flow","description":"Register and Launch a Spring Cloud Task application using Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"822022ec-7c6d-5feb-8563-47bd8672e237","fields":{"path":"/docs/batch-developer-guides/batch/data-flow-spring-batch/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Register and launch a Spring Batch application using Data Flow","description":"Register and launch a Spring Batch application using Data Flow","path":"batch-developer-guides/batch/data-flow-spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"37e8691e-a355-547a-ba39-2e09da52dccb","fields":{"path":"/docs/batch-developer-guides/batch/data-flow-composed-task/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Create and launch a Composed Task using Data Flow","description":"Create and launch a Composed Task using Data Flow","path":"batch-developer-guides/batch/data-flow-composed-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9cdafce3-6786-59ea-be56-7fa3abfe2a8d","fields":{"path":"/docs/batch-developer-guides/batch/data-flow-simple-task-kubernetes/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Deploying a task application on Kubernetes with Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Kubernetes using Spring Cloud Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task-kubernetes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"47726949-2d96-5d2a-b506-85d449fbee7a","fields":{"path":"/docs/batch-developer-guides/batch/data-flow-simple-task-cloudfoundry/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Deploying a task application on Cloud Foundry using Spring Cloud Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Cloud Foundry using Spring Cloud Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task-cloudfoundry/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"89ad65f9-200f-59ed-b88a-2558b39d87a1","fields":{"path":"/docs/batch-developer-guides/continuous-deployment/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Continuous Deployment","description":"Continuous Deployment for task applications","path":"batch-developer-guides/continuous-deployment/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"656700f5-230f-57bb-aaaa-ab849d73c8d4","fields":{"path":"/docs/batch-developer-guides/continuous-deployment/cd-basics/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Continuous Deployment of task applications","description":"This section discusses how to use Continuous Deployment of Tasks in SCDF","path":"batch-developer-guides/continuous-deployment/cd-basics/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b1887ade-7ad5-5fe3-af61-6d78c5a2c391","fields":{"path":"/docs/batch-developer-guides/troubleshooting/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Troubleshooting","description":"Troubleshooting Batch Jobs","path":"batch-developer-guides/troubleshooting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c457deae-ed32-54de-a049-7770e3a325ab","fields":{"path":"/docs/batch-developer-guides/troubleshooting/debugging-task-apps/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Debugging Batch applications","description":"Debugging Batch applications","path":"batch-developer-guides/troubleshooting/debugging-task-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5353c608-5d97-57a4-a736-d1f433cff87a","fields":{"path":"/docs/batch-developer-guides/troubleshooting/debugging-scdf-tasks/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Debugging Batch applications deployed by Data Flow","description":"Debugging Batch applications deployed by Data Flow","path":"batch-developer-guides/troubleshooting/debugging-scdf-tasks/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"725e0e0f-7cd9-5f2a-bcab-b945ccf302c3","fields":{"path":"/docs/feature-guides/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Feature guides","description":"High level overview of Data Flow Features","path":"feature-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b668974e-caee-5353-b9da-f892b2541810","fields":{"path":"/docs/feature-guides/general/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"General","description":"General Features in Data Flow","path":"feature-guides/general/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bfd9e556-3733-532e-b587-7a491b45fd3a","fields":{"path":"/docs/feature-guides/general/application-metadata/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Application Metadata","description":"Create and use application properties metadata","path":"feature-guides/general/application-metadata/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"01a83a22-b8d8-5f7a-944a-5d18ed71f844","fields":{"path":"/docs/feature-guides/streams/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Streams","description":"Stream Features in Data Flow","path":"feature-guides/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bc88a57f-5ead-5fd3-af41-f54dd1057eff","fields":{"path":"/docs/feature-guides/streams/deployment-properties/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Deployment Properties","description":"Initiate a stream deployment with deployment property overrides","path":"feature-guides/streams/deployment-properties/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"7bdab6bf-0057-5fc9-ab6d-997027d023ba","fields":{"path":"/docs/feature-guides/streams/function-composition/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Composing Functions","description":"Daisy-chain Java functions in an existing Spring Cloud Stream application","path":"feature-guides/streams/function-composition/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ed07b36f-0627-57ab-a93d-cb450883437c","fields":{"path":"/docs/feature-guides/streams/named-destinations/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Named Destinations","description":"Use the Named Destinations to interact with the Topics/Queues directly","path":"feature-guides/streams/named-destinations/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e6150ca7-7101-55aa-bded-afc7773ab000","fields":{"path":"/docs/feature-guides/streams/monitoring/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Stream Monitoring","description":"Monitoring streaming data pipelines with Prometheus and InfluxDB","path":"feature-guides/streams/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"7222ffcd-fd1f-5534-801b-ae813d95519d","fields":{"path":"/docs/feature-guides/streams/stream-application-dsl/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Stream Application DSL","description":"Learn how to use the Stream Application DSL","path":"feature-guides/streams/stream-application-dsl/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"59e1ee0d-8052-5d4d-9313-c6f9f6d82624","fields":{"path":"/docs/feature-guides/streams/labels/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Labeling Applications","description":"Label the stream applications to uniquely interact with them","path":"feature-guides/streams/labels/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9920ad80-48f1-50c9-9275-e6a4bb2b0ebb","fields":{"path":"/docs/feature-guides/streams/application-count/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Application Count","description":"Initiate stream deployment with multiple application instances","path":"feature-guides/streams/application-count/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"95edbb8c-cef8-5869-b71a-5dbdffccc74c","fields":{"path":"/docs/feature-guides/streams/fanin-fanout/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Fan-in and Fan-out","description":"Publish and subscribe to multiple destinations using the fan-in and fan-out capabilities","path":"feature-guides/streams/fanin-fanout/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0436a379-399f-55aa-8caa-0f7381ea4d70","fields":{"path":"/docs/feature-guides/streams/partitioning/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Data Partitioning","description":"Learn more about data partitioning support to build stateful streaming data pipelines","path":"feature-guides/streams/partitioning/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8b8b0dd9-9f2d-5fe2-a6f7-946f38490735","fields":{"path":"/docs/feature-guides/streams/scaling/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Scaling","description":"Scaling streaming data pipeline with Spring Cloud Data Flow","path":"feature-guides/streams/scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"844e26f1-494d-54a9-8e04-7c8cf7a217ff","fields":{"path":"/docs/feature-guides/streams/java-dsl/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Java DSL","description":"Programmatically create streams using the Java DSL","path":"feature-guides/streams/java-dsl/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d89b1c27-b48e-5cb8-9b73-03080ae245dd","fields":{"path":"/docs/feature-guides/streams/taps/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Tapping a Stream","description":"Create a stream from another stream without interrupting the data processing","path":"feature-guides/streams/taps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"95ba324d-e79b-5fb8-a887-46f479e0ef0d","fields":{"path":"/docs/feature-guides/batch/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Batch","description":"Batch Features in Data Flow","path":"feature-guides/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3fc82921-18fe-59b0-8e2e-48badfd9482d","fields":{"path":"/docs/feature-guides/batch/deployment-properties/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Deployment Properties","description":"Initiate a Batch deployment with deployment property overrides","path":"feature-guides/batch/deployment-properties/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"32367cc7-7c6c-55de-84a5-a4377abe5ec8","fields":{"path":"/docs/feature-guides/batch/scheduling/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Scheduling Batch Jobs","description":"Learn how to schedule Batch Jobs","path":"feature-guides/batch/scheduling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a56d78fd-7d1f-58f4-8a64-a660b350f5a0","fields":{"path":"/docs/feature-guides/batch/partitioning/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Remote Partitioned Batch Job","description":"Learn more about partitioning support for Batch Jobs","path":"feature-guides/batch/partitioning/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"72583cff-6bbe-5764-95c8-2b351a2b989b","fields":{"path":"/docs/feature-guides/batch/monitoring/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Task Monitoring","description":"Monitoring task data pipelines with InfluxDB","path":"feature-guides/batch/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d95c95c1-e4fd-55aa-bf6a-aa710ecaaefe","fields":{"path":"/docs/feature-guides/batch/restarting/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Restarting Batch Jobs","description":"Learn how to restart Batch Jobs","path":"feature-guides/batch/restarting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5af8ec36-e385-584f-a71f-58fdbc579128","fields":{"path":"/docs/feature-guides/batch/composed-task/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Composed Tasks","description":"Learn how to create and manage composed tasks","path":"feature-guides/batch/composed-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"67bc7142-3c1d-5999-b3f0-28f60b6f9cce","fields":{"path":"/docs/recipes/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Recipes","description":"Recipes that help solve some common use-cases","path":"recipes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"57495018-5ab0-5f3d-b90e-cec60aafe00e","fields":{"path":"/docs/recipes/polyglot/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Polyglot","description":"Using multiple programming languages","path":"recipes/polyglot/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1f105736-34d0-50a5-a15b-57d7df62d52a","fields":{"path":"/docs/recipes/polyglot/processor/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Python Stream Processor","description":"Python Application as a Data Flow Stream Processor","path":"recipes/polyglot/processor/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"74562bf5-fa13-5342-92d1-64045e1cf57a","fields":{"path":"/docs/recipes/polyglot/task/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Python Task","description":"Create and Deploy a Python Task","path":"recipes/polyglot/task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6cd7b11d-24f2-5a23-9618-dc16593ad0e1","fields":{"path":"/docs/recipes/polyglot/app/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Python Application","description":"Create and Deploy a Python Application in a Stream","path":"recipes/polyglot/app/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b071b155-2da5-5e13-9d1b-1373a219acca","fields":{"path":"/docs/recipes/rabbitmq/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"RabbitMQ","description":"RabbitMQ","path":"recipes/rabbitmq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4422320f-2a26-5762-aefc-ebe47cabe5b9","fields":{"path":"/docs/recipes/rabbitmq/rabbit-source-sink/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"RabbitMQ as Source and Sink","description":"RabbitMQ as Source and Sink + RabbitMQ binder","path":"recipes/rabbitmq/rabbit-source-sink/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"937f701e-4ae8-51da-b8d8-b029606333b1","fields":{"path":"/docs/recipes/kafka/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Apache Kafka","description":"Kafka","path":"recipes/kafka/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ccdb90a6-2ff0-5f7b-9bf8-f27eb3dd6b90","fields":{"path":"/docs/recipes/kafka/ext-kafka-cluster-cf/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"External Kafka Cluster","description":"Connect to an external Kafka Cluster from Cloud Foundry","path":"recipes/kafka/ext-kafka-cluster-cf/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"43b48f18-cd3a-59bc-a0ec-76caf1870a2e","fields":{"path":"/docs/recipes/kinesis/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Amazon Kinesis","description":"Amazon Kinesis","path":"recipes/kinesis/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"04e94b39-733b-504d-b157-e22049d538f2","fields":{"path":"/docs/recipes/kinesis/simple-producer-consumer/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Amazon Kinesis Binder","description":"A sample of Spring Cloud Stream + Amazon Kinesis Binder in action","path":"recipes/kinesis/simple-producer-consumer/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"efacb7fd-1868-51a0-86b1-dea163aa05ed","fields":{"path":"/docs/recipes/multi-platform-deployment/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Multiple Platform Deployments","description":"Multiple Platform Deployments","path":"recipes/multi-platform-deployment/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a547204f-8273-536d-b631-5e2caa799077","fields":{"path":"/docs/recipes/multi-platform-deployment/multiple-platform-accounts/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Role of Multiple Platform Deployments","description":"A walk-through of multiple platform requirements and the configurations for Cloud Foundry and Kubernetes","path":"recipes/multi-platform-deployment/multiple-platform-accounts","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ba21954f-491f-55ad-b38a-5f2a548a484f","fields":{"path":"/docs/recipes/scaling/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Scaling","description":"Prometheus and Data Flow to autoscale streaming data pipelines","path":"recipes/scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"74c8179a-6420-50e3-a9fe-a7ac311da03f","fields":{"path":"/docs/recipes/scaling/manual-scaling/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Manual Scaling","description":"Scale applications using SCDF Shell","path":"recipes/scaling/manual-scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1ad32761-7748-5dcc-87c3-97ae4d3ffd36","fields":{"path":"/docs/recipes/scaling/autoscaling/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Autoscaling","description":"Autoscale streaming data pipeline with SCDF and Prometheus","path":"recipes/scaling/autoscaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b9dbd4b8-36aa-59f9-bd36-e899a6016283","fields":{"path":"/docs/recipes/batch/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Batch","description":"Using Spring Cloud Data Flow with Spring Batch","path":"recipes/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9a69777e-f1f3-5d52-a06e-e80e509a34b3","fields":{"path":"/docs/recipes/batch/batch-only-mode/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Batch-only Mode","description":"Set up Spring Cloud Data Flow to use only batch and not streams","path":"recipes/batch/batch-only-mode/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"42aa9dd9-531f-59e6-8bc5-69432fa1234d","fields":{"path":"/docs/recipes/batch/sftp-to-jdbc/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"SFTP to JDBC","description":"Ingest Files from SFTP to a JDBC data store using Data Flow and Spring Batch","path":"recipes/batch/sftp-to-jdbc/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"023388a0-221e-5be9-a14d-1ec0bc3a888c","fields":{"path":"/docs/recipes/functional-apps/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Functional Applications","description":"Using Functional Approach in Spring Cloud Stream applications","path":"recipes/functional-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d5ead5aa-ea33-51ec-b5ec-ac5f85a6289a","fields":{"path":"/docs/recipes/functional-apps/scst-function-bindings/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Functional Applications","description":"Configuring the Spring Cloud Stream Functional applications","path":"recipes/functional-apps/scst-function-bindings/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b6a066e8-6b12-526b-8997-85b6daed059f","fields":{"path":"/docs/recipes/cloud-providers/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Cloud Providers","description":"Using functionality provided by cloud providers","path":"recipes/cloud-providers/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d3e47459-1a4b-553f-92c9-109cef0678ca","fields":{"path":"/docs/recipes/cloud-providers/gke-regional-clusters/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"GKE Regional Clusters","description":"Deploying Spring Cloud Data Flow to a GKE Regional Cluster","path":"recipes/cloud-providers/gke-regional-clusters/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"dce6d220-d80d-5b40-abdd-dccf29666f70","fields":{"path":"/docs/resources/","version":"1.1.0.SNAPSHOT","category":"resources"},"frontmatter":{"title":"Resources","description":"Sample Applications, References Docs, Videos, Blogs...","path":"resources/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f8865a9e-26ca-54dc-8ea4-2c8375814a34","fields":{"path":"/docs/resources/reference-docs/","version":"1.1.0.SNAPSHOT","category":"resources"},"frontmatter":{"title":"Reference Documentation","description":"Collection of reference guides for Spring Cloud Data Flow","path":"resources/reference-docs/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2e2318ef-4892-570b-808e-aaaa2018705f","fields":{"path":"/docs/resources/samples/","version":"1.1.0.SNAPSHOT","category":"resources"},"frontmatter":{"title":"Samples","description":"Collection of samples","path":"resources/samples/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a8f33f41-7d90-5f9f-bc12-86676b11c030","fields":{"path":"/docs/resources/faq/","version":"1.1.0.SNAPSHOT","category":"resources"},"frontmatter":{"title":"Frequently Asked Questions","description":"","path":"resources/faq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"661b356d-d6cd-5d2c-8c09-da1e48979b83","fields":{"path":"/docs/applications/","version":"1.1.0.SNAPSHOT","category":"applications"},"frontmatter":{"title":"Applications","description":"Using stream and task applications","path":"applications/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"060e37c9-d454-519f-ab38-77781d2c00af","fields":{"path":"/docs/applications/pre-packaged/","version":"1.1.0.SNAPSHOT","category":"applications"},"frontmatter":{"title":"Pre-packaged Applications","description":"Pre-packaged stream and task applications","path":"applications/pre-packaged","meta_title":null,"meta_description":null,"keywords":["application","pre-packaged"]}}}]},"page":{"html":"<h2 id=\"快速安装\" style=\"position:relative;\"><a href=\"#%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85\" aria-label=\"快速安装 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>快速安装</h2>\n<p>FusionDB 提供两种安装模式：</p>\n<ul>\n<li>Docker 快速安装体验单机版。</li>\n<li>Anyscale 一体化的产品，可视化的根据安装向导进行安装。</li>\n</ul>\n<p><a href=\"https://github.com/FusionDB/fql-training\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Docker 安装请参阅</a></p>\n<p><a href=\"https://www.fusiondb.cn/docs/installation/local/multi-node/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Anyscale 可视化安装参阅</a></p>\n<h2 id=\"快速访问\" style=\"position:relative;\"><a href=\"#%E5%BF%AB%E9%80%9F%E8%AE%BF%E9%97%AE\" aria-label=\"快速访问 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>快速访问</h2>\n<p>FusionDB 是一个分布式的 OLAP 数据库，兼容 PostgreSQL 协议。用户可以使用标准的 JDBC/ODBC 和 FusionDB 进行交互，示例如下：</p>\n<ul>\n<li>SQL Client 方式</li>\n<li>GUI 工具</li>\n</ul>\n<h3 id=\"sql-client-方式\" style=\"position:relative;\"><a href=\"#sql-client-%E6%96%B9%E5%BC%8F\" aria-label=\"sql client 方式 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SQL Client 方式</h3>\n<p>使用 PostgreSQL 的 psql 与 FusionDB 直接交互或者使用第三方的 pgcli 类工具与 FusionDB 交互。</p>\n<h4 id=\"psql-connects-fusiondb\" style=\"position:relative;\"><a href=\"#psql-connects-fusiondb\" aria-label=\"psql connects fusiondb permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Psql connects FusionDB</h4>\n<ul>\n<li>正常工作，fdb 为超级用户，不需要密码。</li>\n</ul>\n<p>Psql 安装：</p>\n<p>MacOS</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">brew install libpq # or brew install postgresql or brew remove postgresql@11.2\n\n默认路径：/usr/local/opt/libpq/bin/psql</code></pre></div>\n      </div>\n<p>Ubuntu</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">sudo apt-get install postgresql-client</code></pre></div>\n      </div>\n<p>Redhat</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">sudo yum install https://download.postgresql.org/pub/repos/yum/10/redhat/rhel-7-x86_64/pgdg-redhat10-10-2.noarch.rpm\n\nsudo yum install postgresql10</code></pre></div>\n      </div>\n<p><code class=\"language-text\">注意</code>: 如果已安装 postgresql 数据库，则已经自带了 psql，不需要单独安装 client。</p>\n<p>连接方式：</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">psql \"sslmode=disable host=192.168.1.2 port=54322 dbname=default\" --username=fdb\n\ndefault=> show tables;\n default  | boxes          | f\n default  | boxes_1        | f\n\ndefault=> select * from my_table;\n xiaoming |  29\n xiaohua  |  30</code></pre></div>\n      </div>\n<p><code class=\"language-text\">注意</code>: 默认 sslmode=disable，在未来的版本中会 enabled.</p>\n<h4 id=\"pgcli-connects-fusiondb\" style=\"position:relative;\"><a href=\"#pgcli-connects-fusiondb\" aria-label=\"pgcli connects fusiondb permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Pgcli connects FusionDB</h4>\n<ul>\n<li>不正常工作，主要是一些函数不支持，未来会适配。</li>\n</ul>\n<p>连接方式：</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">pgcli 'postgres://fdb:123@172.27.137.232:54322/default?sslmode=disable'</code></pre></div>\n      </div>\n<p>Error:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"exceptiondetected in 'query': cn.fusiondb.fdb.sql.parser.parseexception: missing 'functions' at '<eof>'(line 1, pos 8)\"><pre class=\"language-exceptiondetected in 'query': cn.fusiondb.fdb.sql.parser.parseexception: missing 'functions' at '<eof>'(line 1, pos 8)\"><code class=\"language-exceptiondetected in 'query': cn.fusiondb.fdb.sql.parser.parseexception: missing 'functions' at '<eof>'(line 1, pos 8)\">== SQL ==\nSHOW ALL</code></pre></div>\n      </div>\n<p><code class=\"language-text\">pgcli 参考</code>：<a href=\"https://github.com/dbcli/pgcli\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://github.com/dbcli/pgcli</a></p>\n<h3 id=\"gui-工具\" style=\"position:relative;\"><a href=\"#gui-%E5%B7%A5%E5%85%B7\" aria-label=\"gui 工具 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GUI 工具</h3>\n<p>FusionDB 兼容 PostgreSQL 协议，支持 PostgreSQL 生态的一些可视化 GUI 工具执行 FQL，极大的方便用户快速上手 FusionDB。未来 FusionDB 会支持更多丰富的 SQL 语法。请使用我们测试验证过的第三方工具，否则不保证兼容性。</p>\n<h4 id=\"fusiondb-gui-psequel\" style=\"position:relative;\"><a href=\"#fusiondb-gui-psequel\" aria-label=\"fusiondb gui psequel permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>FusionDB GUI PSequel</h4>\n<ul>\n<li>host：FusionDB SQL Server 主机 IP</li>\n<li>user: fdb</li>\n<li>passowrd: 123456</li>\n<li>database: default</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.49999999999999%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABeklEQVQoz4VS2W7DMAzL/3/fhrXoU9ELTeLcVmwnNSe6SS8MWABCkmNTNOXscrngfD7Htm2xYuha9LWBtA0msYhOMHmHcRxhtR6GASKSahGHEAJut1tUIDudTtEYg6qqogLGVChM0Cjomh7OiiIokcfo9PAU4JXcew+n9eg8pnmOuH8xK4oCr8iLEnnpUZaqpB3gBotx8JDBJVVhmvHXF2NMyMqyxBOFwsBUPeqywTwK9D6IfsQt+KQqhDkd/CRa8zeFJGVUG3BWb7teiZsmoVffGo38z1jXddrfdV2Kh8MBtO6hcCXkkH42GxyPR/RKuN1ukec5rLXY7Xb4+v7mELHf79Me+koyihAd0tuVScrBUJlVv7ihVQXykvMfp8xmXOdgmLMh8+zzuryOV9/SBJXkMc0lX+sVXE+5v78CKoyLwkhCesPO9gWfdYIqkmce5b7v8WziqpCEa2dZcH/A8syX+iOPrDM13L+ScgA0mbher6kBff0HcYn+F4YmSs0506VDAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/27935818c0a92c97563bae7661683c33/507e6/psequel-gui.webp 200w,\n/static/27935818c0a92c97563bae7661683c33/28a80/psequel-gui.webp 400w,\n/static/27935818c0a92c97563bae7661683c33/8d2ea/psequel-gui.webp 800w,\n/static/27935818c0a92c97563bae7661683c33/68fc1/psequel-gui.webp 1200w,\n/static/27935818c0a92c97563bae7661683c33/43d96/psequel-gui.webp 1600w,\n/static/27935818c0a92c97563bae7661683c33/a662b/psequel-gui.webp 2560w\"\n              sizes=\"(max-width: 800px) 100vw, 800px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/27935818c0a92c97563bae7661683c33/36ca5/psequel-gui.png 200w,\n/static/27935818c0a92c97563bae7661683c33/a3397/psequel-gui.png 400w,\n/static/27935818c0a92c97563bae7661683c33/a331c/psequel-gui.png 800w,\n/static/27935818c0a92c97563bae7661683c33/8537d/psequel-gui.png 1200w,\n/static/27935818c0a92c97563bae7661683c33/1a152/psequel-gui.png 1600w,\n/static/27935818c0a92c97563bae7661683c33/6d719/psequel-gui.png 2560w\"\n            sizes=\"(max-width: 800px) 100vw, 800px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/27935818c0a92c97563bae7661683c33/a331c/psequel-gui.png\"\n            alt=\"FusionDB GUI\"\n            title=\"FusionDB GUI\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n    </span></p>\n<p><code class=\"language-text\">注意</code>：使用 Mac 版本进行测试，连接 <code class=\"language-text\">Use SSL</code> 选项不勾选，默认即可，目前还未支持 <code class=\"language-text\">Use SSL</code>模式。</p>\n<p>如下几个简单的示例，让我们来快速认识 FusionDB SQL 语法吧。</p>\n<h5 id=\"fusiondb-join-psequel\" style=\"position:relative;\"><a href=\"#fusiondb-join-psequel\" aria-label=\"fusiondb join psequel permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>FusionDB Join Psequel</h5>\n<ol>\n<li>Load HDFS File</li>\n</ol>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">load 'hdfs://jdp-2:8020/tmp/spark-tpcds-data/store_sales' format parquet AS store_sales;\n\nSELECT * FROM store_sales LIMIT 200;\n\nshow tables;</code></pre></div>\n      </div>\n<ol start=\"2\">\n<li>Load RDBMS Table</li>\n<li>Load MySQL Table</li>\n</ol>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">load 'mysql' options('url'='jdbc:mysql://mysql-test1:3306/test','dbtable'='person','user'= 'root','password'='root') AS mysql_t2;\n\nSELECT * FROM mysql_t2;</code></pre></div>\n      </div>\n<ul>\n<li>Load PostgreSQL table</li>\n</ul>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">load 'postgresql' options('url'='jdbc:postgresql://pg-server-1:5430/test','dbtable'='person','user'= 'xujiang','password'='123') AS gp_t1;\n\nSELECT * FROM gp_t1;</code></pre></div>\n      </div>\n<ul>\n<li>MySQL Table Join PostgreSQL Table</li>\n</ul>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">SELECT * FROM mysql_t2 LEFT JOIN gp_t1 ON mysql_t2.id = gp_t1.id;\n\nSELECT * FROM mysql_t2;</code></pre></div>\n      </div>\n<ul>\n<li>Load datasource in query</li>\n</ul>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Case1: query all data\n\nload 'mysql' options('url'='jdbc:mysql://your_hostname:53306/test','dbtable'='t1','user'='root','password'='root') AS mysql_t2;\n\nSELECT * FROM mysql_t2;\n\nCase2: query supports pushdown\n\nload 'mysql' options('url'='jdbc:mysql://your_hostname:53306/test','query'='select * from test.t1 where id=2','user'='root','password'='root') AS mysql_t2;\n\nSELECT * FROM mysql_t2;</code></pre></div>\n      </div>\n<p>关于 <code class=\"language-text\">Oracle，Greenplum，DB2，SQLServer，Teradata，Data Lake</code> 使用示例。请参阅<a href=\"http://www.fusionlab.cn/zh-cn/fdb/data-sources.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Data Sources</a></p>\n<ol start=\"3\">\n<li>Save table to HDFS</li>\n</ol>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">save APPEND gauss_t1 TO 'hdfs://jdp-2:8020/tmp/pg_test' format parquet;\n\nsave overwrite mysql_t2 TO 'hdfs://jdp-2:8020/tmp/pg_test' FORMAT PARQUET;\n\nload 'hdfs://jdp-2:8020/tmp/pg_test' format parquet AS pg_test;\n\nSELECT * FROM pg_test;</code></pre></div>\n      </div>\n<ol start=\"4\">\n<li>Create Table in HDFS parquet</li>\n</ol>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">CREATE [TEMPORARY] TABLE [IF NOT EXISTS] [db_name.]table_name\n  [(col_name1 col_type1 [COMMENT col_comment1], ...)]\n  USING datasource\n  [OPTIONS (key1=val1, key2=val2, ...)]\n  [PARTITIONED BY (col_name1, col_name2, ...)]\n  [CLUSTERED BY (col_name3, col_name4, ...) INTO num_buckets BUCKETS]\n  [LOCATION path]\n  [COMMENT table_comment]\n  [TBLPROPERTIES (key1=val1, key2=val2, ...)]\n  [AS select_statement]</code></pre></div>\n      </div>\n<p>Examples</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">## create table in parquet/orc/csv/textfile/etc.\n\nCREATE TABLE t3 USING parquet Options(path 'hdfs://plat-xujiang-cdsw:8020/tmp/web_site_test');\n\nCREATE TABLE web_site_test USING PARQUET LOCATION 'hdfs://plat-xujiang-cdsw:8020/tmp/web_site_test';\n\n## Create table\n\nCase1:\n\nCREATE TABLE t11 (`id` BIGINT, `name` STRING, `age` INT, `birthday` DATE);\n\nINSERT INTO TABLE t11 values(1, '百度', 10, now()),(2, '阿里', 12, now());\n\nSELECT * FROM t11;\n\nCREATE TABLE boxes (width INT, length INT, height INT) USING CSV;\n\nINSERT INTO TABLE boxes values(1, 33, 222),(2, 99, 888);\n\nSELECT * FROM boxes;\n\nCase 2:\n\nCREATE TABLE boxes_1(width INT, length INT, height INT)\n  USING PARQUET\n  OPTIONS ('compression'='snappy');\n\nINSERT INTO TABLE boxes_1 values(1, 33, 222),(2, 99, 888);\n\nSELECT * FROM boxes_1;\n\nCREATE TABLE boxes_5(width INT, length INT, height INT)\n  USING ORC\n  OPTIONS ('compression'='snappy');\n\nINSERT INTO TABLE boxes_5 values(1, 33, 222),(2, 99, 888);\n\nSELECT * FROM boxes_5;\n\nCREATE TABLE boxes_6(width INT, length INT, height INT)\n  USING CSV\n  OPTIONS ('compression'='snappy');\n\nINSERT INTO TABLE boxes_6 values(1, 33, 222),(2, 99, 888);\n\nSELECT * FROM boxes_6;\n\n## Create temporary table\nCREATE TEMPORARY TABLE boxes\n  (width INT, length INT, height INT)\n  USING PARQUET\n  OPTIONS ('compression'='snappy')\n\n## Create parquet table with select result\nCREATE TABLE rectangles\n  USING PARQUET\n  PARTITIONED BY (width)\n  CLUSTERED BY (length) INTO 8 buckets\n  AS SELECT * FROM boxes</code></pre></div>\n      </div>\n<ol start=\"5\">\n<li>Create Table with Hive format</li>\n</ol>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">CREATE [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name\n  [(col_name1[:] col_type1 [COMMENT col_comment1], ...)]\n  [COMMENT table_comment]\n  [PARTITIONED BY (col_name2[:] col_type2 [COMMENT col_comment2], ...)]\n  [ROW FORMAT row_format]\n  [STORED AS file_format]\n  [LOCATION path]\n  [TBLPROPERTIES (key1=val1, key2=val2, ...)]\n  [AS select_statement]\n\nrow_format:\n  : SERDE serde_cls [WITH SERDEPROPERTIES (key1=val1, key2=val2, ...)]\n  | DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]]\n      [COLLECTION ITEMS TERMINATED BY char]\n      [MAP KEYS TERMINATED BY char]\n      [LINES TERMINATED BY char]\n      [NULL DEFINED AS char]\n\nfile_format:\n  : TEXTFILE | SEQUENCEFILE | RCFILE | ORC | PARQUET | AVRO\n  | INPUTFORMAT input_fmt OUTPUTFORMAT output_fmt</code></pre></div>\n      </div>\n<p>Examples</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">DROP TABLE my_table;\n\nCREATE TABLE my_table (name STRING, age INT);\n\nINSERT INTO TABLE my_table values('xiaoming', 29),('xiaohua', 30);\n\nSELECT * FROM my_table;\n\nCREATE TABLE my_table_1 (name STRING, age INT)\n  COMMENT 'This table is partitioned'\n  PARTITIONED BY (hair_color STRING COMMENT 'This is a column comment')\n  TBLPROPERTIES ('status'='staging', 'owner'='andrew');\n\nCREATE TABLE my_table_2 (name STRING, age INT)\n  COMMENT 'This table specifies a custom SerDe'\n  ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.orc.OrcSerde'\n  STORED AS\n      INPUTFORMAT 'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat'\n      OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat';\n\nCREATE TABLE my_table_3 (name STRING, age INT)\n  COMMENT 'This table uses the CSV format'\n  ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n  STORED AS TEXTFILE;\n\nCREATE TABLE your_table\n  COMMENT 'This table is created with existing data'\n  AS SELECT * FROM my_table;\n\nCREATE EXTERNAL TABLE IF NOT EXISTS my_table_4 (name STRING, age INT)\n  COMMENT 'This table is created with existing data'\n  LOCATION 'spark-warehouse/tables/my_existing_table';\n\nSELECT * FROM my_table_4;\n\n## Create Table Like\n\nCREATE TABLE IF NOT EXISTS default.tt1 LIKE default.t3 LOCATION 'hdfs://plat-xujiang-cdsw:8020/tmp/web_site_test';\n\nSELECT * FROM tt1;</code></pre></div>\n      </div>\n<p>注意：选中想要执行的语句，点击运行按钮进行 FQL 的执行。此工具选中多条 FQL 执行时，逗号分隔，不支持执行，由于是第三方工具，目前暂未修复此问题。</p>\n<h5 id=\"fusiondb-join-pandas\" style=\"position:relative;\"><a href=\"#fusiondb-join-pandas\" aria-label=\"fusiondb join pandas permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>FusionDB Join Pandas</h5>\n<ol>\n<li>Psycopg2 connecting FDB</li>\n</ol>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">import psycopg2\nimport pandas as pd\nconnection = psycopg2.connect(“host=localhost port=5432 dbname=default user=xujiang sslmode=disable”)\ndf = pd.read_sql(sql=”SELECT * FROM VALUES (1, 1), (1, 2) AS t(a, b);”, con=connection)\ndf\na b\n0 1 1\n1 1 2\ndf = pd.read_sql(sql=”show databases;”, con=connection)\ndf = pd.read_sql(sql=”show tables;”, con=connection)</code></pre></div>\n      </div>\n<p>注: psycopg2 连接时，需要 <code class=\"language-text\">sslmode=disable</code>，因为还未支持，未来版本会支持。</p>\n<ol start=\"2\">\n<li>Local csv file to parquet</li>\n</ol>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">df = pd.read_sql(sql=”load ‘file:///data/github/fusiondb/data/csv/‘ format csv options(‘inferSchema’=’true’, ‘header’=’true’) as t1”, con=connection)\n\ndf =pd.read_sql(sql=”desc t1”, con=connection)\ndf = pd.read_sql(sql=”save APPEND T1 TO ‘file:///data/github/fusiondb/data/csv/t1‘ format parquet”, con=connection)</code></pre></div>\n      </div>\n<ol start=\"2\">\n<li>Load csv file to HDFS parquet</li>\n</ol>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">df = pd.read_sql(sql=”load ‘file:////data/github/fusiondb/data/userdata2.parquet’ format parquet as c2;”, con=connection)\n\ndf = pd.read_sql(sql=”save APPEND T1 TO ‘hdfs://jdp-1:8020/tmp/t1‘ FORMAT PARQUET;”, con=connection)\n\ndf =pd.read_sql(sql=”load ‘hdfs://jdp-1:8020/tmp/t1‘ format parquet as t2;”, con=connection)\n\ndf =pd.read_sql(sql=”show tables;”, con=connection)\n\ndf =pd.read_sql(sql=”desc t2;”, con=connection)</code></pre></div>\n      </div>\n<ol start=\"3\">\n<li>Load parquet file to MySQL t3</li>\n</ol>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">df = pd.read_sql(sql=”load ‘file:////data/github/fusiondb/data/userdata2.parquet’ format parquet as c2;”, con=connection)\n\ndf = pd.read_sql(sql=”save overwrite c2 TO ‘hdfs://jdp-1:8020/tmp/t1‘ FORMAT PARQUET;”, con=connection)\n\ndf = pd.read_sql(sql=”load ‘hdfs://jdp-1:8020/tmp/t1‘ format parquet as h1”, con=connection)\n\ndf = pd.read_sql(sql=”select * from h1”, con=connection)\ndf.head()\n\ndf = pd.read_sql(sql=”select current_database();”, con=connection)\n\ndf = pd.read_sql(sql=”save h1 to ‘mysql’ options(‘url’=”jdbc:mysql://mysql-server:3306/test”,’dbtable’=’h1,’user’= ‘test’,’password’=’123’);”, con=connection)</code></pre></div>\n      </div>\n<h2 id=\"faq\" style=\"position:relative;\"><a href=\"#faq\" aria-label=\"faq permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>FAQ</h2>\n<ul>\n<li>关于 MYSQL，PostgreSQL 驱动：需要自己下载安装到 JDP 的 FusionDB lib 目录下，才可以正常使用。</li>\n<li>关于支持从 Local 加载数据：这里指的 Local 是 FusionDB SQL Server 安装节点 Linux 本机本地的数据。开发调试时 Local 模式安装，能做到 Local 到集群的读写操作，生产环境目前不建议如此。</li>\n<li>关于 FusionDB SQL 语法支持：支持 SQL 99 标准，其他 SQL++ 部分是自己扩展的 SQL 语法，未来功能请关注 roadmap 。</li>\n<li>关于跨多云协作、查询、分析：在下一个版本 release，目前未测试稳定。</li>\n<li>关于 <code class=\"language-text\">Data Lake</code> 支持事物，实时、批量写数据： 在下一个版本 release，目前未测试稳定。</li>\n<li>关于 <code class=\"language-text\">Data Lake</code> 支持批流语法统一，批流数据一致问题： 在下一个版本 release，目前未测试稳定。</li>\n<li>关于，FQL 除标准 SQL 外，一些 SQL++</li>\n</ul>\n<p>语法为何这样丑，完全不像是做数据库的人弄出来的语法：早期设计问题，对事物规律的统一归纳考虑不全。Next 批流语法统一时，会遵循标准数据库语法，扩展新的语法时，尽量不造新概念。作者也是在努力学习如何做一个数据库呢，请圈内的大佬们多包涵。</p>","headings":[{"value":"快速安装","depth":2},{"value":"快速访问","depth":2},{"value":"SQL Client 方式","depth":3},{"value":"Psql connects FusionDB","depth":4},{"value":"Pgcli connects FusionDB","depth":4},{"value":"GUI 工具","depth":3},{"value":"FusionDB GUI PSequel","depth":4},{"value":"FusionDB Join Psequel","depth":5},{"value":"FusionDB Join Pandas","depth":5},{"value":"FAQ","depth":2}],"fields":{"path":"/docs/sql-developer-guides/getting-started/sql/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides","sourcePath":"pages/11-sql-developer-guides/1-getting-started/1-sql.md"},"frontmatter":{"title":"SQL Using","summary":null,"path":"sql-developer-guides/getting-started/sql/","toc":null,"prevNext":null}}},"pageContext":{"slug":"/docs/sql-developer-guides/getting-started/sql/","version":"1.1.0.SNAPSHOT","versionPath":""}},"staticQueryHashes":["1084522749","2044043181"]}