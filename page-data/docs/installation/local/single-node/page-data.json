{"componentChunkName":"component---src-templates-documentation-js","path":"/docs/installation/local/single-node/","result":{"data":{"pages":{"edges":[{"node":{"id":"3ecc7a35-a4a0-50f5-8ca3-075cb1a85294","fields":{"path":"/docs/installation/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Installation","description":"How to install anyscale","path":"installation/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f1c53ccb-0064-51d7-9b7f-54c6ed432f18","fields":{"path":"/docs/installation/local/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Local Machine","description":"Local Machine Installation Guide","path":"installation/local/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6b228ad2-818d-5a06-901a-9521fe71a005","fields":{"path":"/docs/installation/local/single-node/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Single Node","description":"Installation using Single Node","path":"installation/local/single-node","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a29b5f60-603c-5a7d-a603-cb9ecb42ffdf","fields":{"path":"/docs/installation/local/multi-node/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Multi Node","description":"Installation using Multi Node","path":"installation/local/multi-node","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"96b33d1e-fb27-5955-9776-3f9b77560759","fields":{"path":"/docs/installation/local/manual/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Manual","description":"Manual installation","path":"installation/local/manual","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3b872bda-042a-53b9-ab03-5f7848a87255","fields":{"path":"/docs/installation/cloud/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Cloud","description":"Anyscale Stack Cloud Installation Guide","path":"installation/cloud/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ba9614fa-3aff-5dd8-b878-c52a1964543f","fields":{"path":"/docs/installation/cloud/cf-cli/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Cloud CLI","description":"Install using the Cloud CLI","path":"installation/cloud/cf-cli","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8d0bc514-d33a-56ed-9971-14a938514a19","fields":{"path":"/docs/installation/cloud/cf-local/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Running locally","description":"Configure the local servers to deploy to Cloud","path":"installation/cloud/cf-local","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e193dae4-0551-5e09-8b67-c69700058ecc","fields":{"path":"/docs/installation/kubernetes/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Kubernetes","description":"Data Flow Kubernetes Installation Guide","path":"installation/kubernetes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"71fabca3-63cd-5032-8d07-d4f066daeb11","fields":{"path":"/docs/installation/kubernetes/creating-a-cluster/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Creating a Cluster","description":"Creating a Kubernetes Cluster","path":"installation/kubernetes/creating-a-cluster","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0b8a6e6c-ddc2-5ad9-8ebc-dd0e342c440f","fields":{"path":"/docs/installation/kubernetes/helm/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Helm","description":"Installation using Helm","path":"installation/kubernetes/helm","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"591ecf46-8124-5175-b61c-5f0265ac12e9","fields":{"path":"/docs/installation/kubernetes/kubectl/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"kubectl","description":"Installation using kubectl","path":"installation/kubernetes/kubectl","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4ce9650d-67dd-50c9-8e50-2e704698a547","fields":{"path":"/docs/installation/kubernetes/compatibility/","version":"1.1.0.SNAPSHOT","category":"installation"},"frontmatter":{"title":"Kubernetes Compatibility","description":"Compatibility with Kubernetes Versions","path":"installation/kubernetes/compatibility","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2c6cc459-6e7a-5ded-b630-f243a9b9f1ff","fields":{"path":"/docs/design/","version":"1.1.0.SNAPSHOT","category":"design"},"frontmatter":{"title":"Design","description":"FusionDB design guides","path":"design/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"25779935-8431-5dfa-9a92-a74d2fc66380","fields":{"path":"/docs/design/concept/","version":"1.1.0.SNAPSHOT","category":"design"},"frontmatter":{"title":"Concept","description":"design of concept","path":"design/concept/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f08eaac6-83c1-59a7-9be1-25f752d46151","fields":{"path":"/docs/design/fql/","version":"1.1.0.SNAPSHOT","category":"design"},"frontmatter":{"title":"SQL Layer","description":"SQL Layer","path":"design/fql/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6c48db2b-fc36-593e-9670-3d1450fcdd3f","fields":{"path":"/docs/design/core/","version":"1.1.0.SNAPSHOT","category":"design"},"frontmatter":{"title":"Core Layer","description":"core layer","path":"design/core/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e478f290-68f6-5615-b8a6-97088d76eec5","fields":{"path":"/docs/design/runtime/","version":"1.1.0.SNAPSHOT","category":"design"},"frontmatter":{"title":"Runtime","description":"runtime","path":"design/runtime/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d2b195f9-0bca-560c-8b5a-dbdc5520e735","fields":{"path":"/docs/design/developer/","version":"1.1.0.SNAPSHOT","category":"design"},"frontmatter":{"title":"Developer","description":"developer","path":"design/developer/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ec04335a-97ce-57c7-995f-9e4d96db6049","fields":{"path":"/docs/sql-developer-guides/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"SQL Developer guides ","description":"Learn how to create Batch data pipelines using prebuilt microservices or create your own","path":"sql-developer-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"429988e7-5aa5-50a3-8cf0-338ba884fa7f","fields":{"path":"/docs/sql-developer-guides/getting-started/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Getting Started","description":"Getting Started with SQL","path":"sql-developer-guides/getting-started/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3d73e2f0-ac02-50de-ba80-41711b3a186c","fields":{"path":"/docs/sql-developer-guides/getting-started/sql/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"SQL Using","description":"快速利用 Docker 安装 FusionDB 单机版，体验 FusionDB 相关功能","path":"sql-developer-guides/getting-started/sql/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"54553db1-36d8-5b13-9fa6-cff7a3f3a21e","fields":{"path":"/docs/sql-developer-guides/getting-started/task/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"SQL Processing","description":"Create and deploy a simple Task pipeline using a prebuilt Task application on your local machine","path":"sql-developer-guides/getting-started/task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"346fd6a4-609d-5ad1-ae8c-a45bced7ce47","fields":{"path":"/docs/sql-developer-guides/getting-started/datasource/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"SQL DataSource","description":"使用 SQL 进行联邦数据查询，多数据源聚合分析","path":"sql-developer-guides/getting-started/datasource/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f33ed054-c323-5eb9-bbd7-85964bf4e09a","fields":{"path":"/docs/sql-developer-guides/sql/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"SQL Development","description":"SQL Developer Guide","path":"sql-developer-guides/sql/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c375337c-f867-53a7-b11a-d240bd310ac3","fields":{"path":"/docs/sql-developer-guides/sql/spring-task/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Simple Task","description":"Create a simple Spring Boot Application using Spring Cloud Task","path":"sql-developer-guides/sql/spring-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ea8201ae-04f1-50ec-9f8a-6a387609dfe0","fields":{"path":"/docs/sql-developer-guides/sql/spring-batch/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Spring Batch Jobs","description":"Create a Spring Batch Job","path":"sql-developer-guides/sql/spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5c9729b3-3021-564f-8eb2-a8321406b98a","fields":{"path":"/docs/sql-developer-guides/sql/data-flow-simple-task/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Register and Launch a Spring Cloud Task application using Data Flow","description":"Register and Launch a Spring Cloud Task application using Data Flow","path":"sql-developer-guides/sql/data-flow-simple-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"49525935-e0f0-562f-813b-2d29105d7467","fields":{"path":"/docs/sql-developer-guides/sql/data-flow-spring-batch/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Register and launch a Spring Batch application using Data Flow","description":"Register and launch a Spring Batch application using Data Flow","path":"sql-developer-guides/sql/data-flow-spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6f865c8f-c501-59bd-bdd3-379176588fa1","fields":{"path":"/docs/sql-developer-guides/sql/data-flow-composed-task/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Create and launch a Composed Task using Data Flow","description":"Create and launch a Composed Task using Data Flow","path":"sql-developer-guides/sql/data-flow-composed-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"cc37c6e1-2257-5e0e-96cc-5cd43a2def6b","fields":{"path":"/docs/sql-developer-guides/sql/data-flow-simple-task-kubernetes/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Deploying a task application on Kubernetes with Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Kubernetes using Spring Cloud Data Flow","path":"sql-developer-guides/sql/data-flow-simple-task-kubernetes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"93b44426-31a6-544a-86b2-35f3ba014ae3","fields":{"path":"/docs/sql-developer-guides/sql/data-flow-simple-task-cloudfoundry/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Deploying a task application on Cloud Foundry using Spring Cloud Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Cloud Foundry using Spring Cloud Data Flow","path":"sql-developer-guides/sql/data-flow-simple-task-cloudfoundry/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3484ded6-4802-5492-a292-6c9e78deb100","fields":{"path":"/docs/sql-developer-guides/continuous-deployment/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Continuous Deployment","description":"Continuous Deployment for task applications","path":"sql-developer-guides/continuous-deployment/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e3efa0fd-52c6-5594-92d8-8b098a0a8642","fields":{"path":"/docs/sql-developer-guides/continuous-deployment/cd-basics/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Continuous Deployment of task applications","description":"This section discusses how to use Continuous Deployment of Tasks in SCDF","path":"sql-developer-guides/continuous-deployment/cd-basics/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e2213760-12ff-5dfc-aba5-ab56971e577f","fields":{"path":"/docs/sql-developer-guides/troubleshooting/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Troubleshooting","description":"Troubleshooting Batch Jobs","path":"sql-developer-guides/troubleshooting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2396db76-6ce6-5fa0-b5ac-102773364cc1","fields":{"path":"/docs/sql-developer-guides/troubleshooting/debugging-task-apps/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Debugging Batch applications","description":"Debugging Batch applications","path":"sql-developer-guides/troubleshooting/debugging-task-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2320f09c-15d7-51cd-9b17-0e8846542fc4","fields":{"path":"/docs/sql-developer-guides/troubleshooting/debugging-scdf-tasks/","version":"1.1.0.SNAPSHOT","category":"sql-developer-guides"},"frontmatter":{"title":"Debugging Batch applications deployed by Data Flow","description":"Debugging Batch applications deployed by Data Flow","path":"sql-developer-guides/troubleshooting/debugging-scdf-tasks/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"fea3a6a4-a66e-5cfd-9b37-ca898f5b5190","fields":{"path":"/docs/concepts/","version":"1.1.0.SNAPSHOT","category":"concepts"},"frontmatter":{"title":"Concepts","description":"Core Concepts in Spring Cloud Data Flow","path":"concepts/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"21618e29-2e26-5a55-bf21-b2558a3d03a3","fields":{"path":"/docs/concepts/architecture/","version":"1.1.0.SNAPSHOT","category":"concepts"},"frontmatter":{"title":"Architecture","description":"Introduction to Anyscale Architecture.","path":"concepts/architecture/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"088d6d89-b0c0-5c37-8dcd-2ac0419a071e","fields":{"path":"/docs/concepts/streams/","version":"1.1.0.SNAPSHOT","category":"concepts"},"frontmatter":{"title":"Stream Processing","description":"Stream Processing Framework and Concepts","path":"concepts/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1566bdae-fbc5-58a7-b344-2c78c931d617","fields":{"path":"/docs/concepts/batch-jobs/","version":"1.1.0.SNAPSHOT","category":"concepts"},"frontmatter":{"title":"Batch Processing","description":"Batch Processing Framework and Concepts","path":"concepts/batch-jobs/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a3ba7d4b-fb03-517c-9839-8e8197ed9014","fields":{"path":"/docs/concepts/monitoring/","version":"1.1.0.SNAPSHOT","category":"concepts"},"frontmatter":{"title":"Monitoring","description":"Runtime monitoring of Stream data pipelines","path":"concepts/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"18e13ddd-6f0b-5b14-b11f-679043097e42","fields":{"path":"/docs/concepts/tooling/","version":"1.1.0.SNAPSHOT","category":"concepts"},"frontmatter":{"title":"Tooling","description":"Dashboard and Shell","path":"concepts/tooling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1d5310d0-b1de-5013-9e17-95b19fb87203","fields":{"path":"/docs/concepts/sql/","version":"1.1.0.SNAPSHOT","category":"concepts"},"frontmatter":{"title":"SQL Processing","description":"SQL Processing and Concepts","path":"concepts/sql/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"644a733d-86e6-55b3-bb24-ffd61e3d7118","fields":{"path":"/docs/concepts/roadmap/","version":"1.1.0.SNAPSHOT","category":"concepts"},"frontmatter":{"title":"Roadmap","description":"开发计划","path":"concepts/roadmap/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"fd71c04a-5a0e-5af0-b320-e9358351d3ea","fields":{"path":"/docs/stream-developer-guides/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Developer guides ","description":"Learn how to create Streaming data pipelines using prebuilt microservices or create your own.","path":"stream-developer-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3596d1cf-579d-5ac4-8387-1ea4634fd0e5","fields":{"path":"/docs/stream-developer-guides/getting-started/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Getting Started","description":"Getting Started with Stream Processing","path":"stream-developer-guides/getting-started/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"cf299cf6-53fc-53b1-bd36-62d5d29c6ade","fields":{"path":"/docs/stream-developer-guides/getting-started/stream/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Processing","description":"Create and deploy a streaming data pipeline using prebuilt applications on your Local Machine","path":"stream-developer-guides/getting-started/stream/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c8d2f6d4-17d1-5f54-8757-4466f5d33695","fields":{"path":"/docs/stream-developer-guides/streams/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Development","description":"Stream Processing Developer Guide","path":"stream-developer-guides/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6d2b5081-b96c-5152-8b40-333964ca9825","fields":{"path":"/docs/stream-developer-guides/streams/standalone-stream-rabbitmq/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Application Development on RabbitMQ","description":"Create your own microservices for Stream processing using RabbitMQ and deploy them manually","path":"stream-developer-guides/streams/standalone-stream-rabbitmq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6b69dd51-76d7-5027-a6ee-a6872d1d9049","fields":{"path":"/docs/stream-developer-guides/streams/standalone-stream-kafka/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Application Development on Apache Kafka","description":"Create your own microservices for Stream processing using Apache Kafka and deploy them manually","path":"stream-developer-guides/streams/standalone-stream-kafka/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bffc856f-d9e2-5c65-8bcc-324342396303","fields":{"path":"/docs/stream-developer-guides/streams/data-flow-stream/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Stream Processing using Spring Cloud Data Flow","description":"Create and Deploy a Stream Processing Pipeline using Spring Cloud Data Flow","path":"stream-developer-guides/streams/data-flow-stream/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2dd6ce45-117d-5a25-9367-075e79d52587","fields":{"path":"/docs/stream-developer-guides/streams/stream-other-binders/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Spring Application Development on other Messaging Middleware","description":"Create your own microservices for Stream processing using other messaging middleware such as Google Pub/Sub, Amazon Kinesis, and Solace JMS","path":"stream-developer-guides/streams/stream-other-binders/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9fa08430-1f7b-5dde-a0fc-03817e2a4c37","fields":{"path":"/docs/stream-developer-guides/programming-models/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Programming Models","description":"Programming models","path":"stream-developer-guides/programming-models/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"cc059c39-c9e5-5540-9d08-a588822b7388","fields":{"path":"/docs/stream-developer-guides/continuous-delivery/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Continuous Delivery","description":"CD using Skipper","path":"stream-developer-guides/continuous-delivery/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"dc4df21a-da51-5281-ade7-5440d0d54ea7","fields":{"path":"/docs/stream-developer-guides/continuous-delivery/cd-basics/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Continuous Delivery of streaming applications","description":"Continuous Delivery of Streaming applications","path":"stream-developer-guides/continuous-delivery/cd-basics/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a7cb53c4-542c-52f0-a10b-9c0677f21d5e","fields":{"path":"/docs/stream-developer-guides/troubleshooting/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Troubleshooting","description":"Troubleshooting Streams","path":"stream-developer-guides/troubleshooting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bb657862-05a5-5951-8aa6-edf9434bf3e6","fields":{"path":"/docs/stream-developer-guides/troubleshooting/debugging-stream-apps/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Debugging Stream Applications","description":"Debugging Stream Applications outside of Data Flow","path":"stream-developer-guides/troubleshooting/debugging-stream-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"22c370d7-851f-5413-9a1e-14e785767cf4","fields":{"path":"/docs/stream-developer-guides/troubleshooting/debugging-scdf-streams/","version":"1.1.0.SNAPSHOT","category":"stream-developer-guides"},"frontmatter":{"title":"Debugging Stream applications deployed by Data Flow","description":"Debugging Data Flow Stream deployments","path":"stream-developer-guides/troubleshooting/debugging-scdf-streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"82ed2c33-4e67-5756-ad9f-edfbbb4b4ca8","fields":{"path":"/docs/batch-developer-guides/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Batch Developer guides ","description":"Learn how to create Batch data pipelines using prebuilt microservices or create your own","path":"batch-developer-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"369db1c1-0310-5da7-9905-458db85318ee","fields":{"path":"/docs/batch-developer-guides/getting-started/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Getting Started","description":"Getting Started with Batch","path":"batch-developer-guides/getting-started/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f01266d1-bfea-5f1c-bab2-05d7906ba57c","fields":{"path":"/docs/batch-developer-guides/getting-started/task/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Task Processing","description":"Create and deploy a simple Task pipeline using a prebuilt Task application on your local machine","path":"batch-developer-guides/getting-started/task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9e12315c-9a3d-5bac-960c-deecca24953e","fields":{"path":"/docs/batch-developer-guides/batch/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Batch Development","description":"Batch Developer Guide","path":"batch-developer-guides/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2fc4857f-a714-533f-ab6a-060f5fc6e978","fields":{"path":"/docs/batch-developer-guides/batch/spring-task/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Simple Task","description":"Create a simple Spring Boot Application using Spring Cloud Task","path":"batch-developer-guides/batch/spring-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0c71d5bb-707f-58c9-941a-2cb3d73ff346","fields":{"path":"/docs/batch-developer-guides/batch/spring-batch/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Spring Batch Jobs","description":"Create a Spring Batch Job","path":"batch-developer-guides/batch/spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"85dfbeaf-2236-53d0-8c6b-fb08ca9f0ef4","fields":{"path":"/docs/batch-developer-guides/batch/data-flow-simple-task/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Register and Launch a Spring Cloud Task application using Data Flow","description":"Register and Launch a Spring Cloud Task application using Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"822022ec-7c6d-5feb-8563-47bd8672e237","fields":{"path":"/docs/batch-developer-guides/batch/data-flow-spring-batch/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Register and launch a Spring Batch application using Data Flow","description":"Register and launch a Spring Batch application using Data Flow","path":"batch-developer-guides/batch/data-flow-spring-batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"37e8691e-a355-547a-ba39-2e09da52dccb","fields":{"path":"/docs/batch-developer-guides/batch/data-flow-composed-task/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Create and launch a Composed Task using Data Flow","description":"Create and launch a Composed Task using Data Flow","path":"batch-developer-guides/batch/data-flow-composed-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9cdafce3-6786-59ea-be56-7fa3abfe2a8d","fields":{"path":"/docs/batch-developer-guides/batch/data-flow-simple-task-kubernetes/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Deploying a task application on Kubernetes with Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Kubernetes using Spring Cloud Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task-kubernetes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"47726949-2d96-5d2a-b506-85d449fbee7a","fields":{"path":"/docs/batch-developer-guides/batch/data-flow-simple-task-cloudfoundry/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Deploying a task application on Cloud Foundry using Spring Cloud Data Flow","description":"Guide to deploying spring-cloud-stream-task applications on Cloud Foundry using Spring Cloud Data Flow","path":"batch-developer-guides/batch/data-flow-simple-task-cloudfoundry/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"89ad65f9-200f-59ed-b88a-2558b39d87a1","fields":{"path":"/docs/batch-developer-guides/continuous-deployment/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Continuous Deployment","description":"Continuous Deployment for task applications","path":"batch-developer-guides/continuous-deployment/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"656700f5-230f-57bb-aaaa-ab849d73c8d4","fields":{"path":"/docs/batch-developer-guides/continuous-deployment/cd-basics/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Continuous Deployment of task applications","description":"This section discusses how to use Continuous Deployment of Tasks in SCDF","path":"batch-developer-guides/continuous-deployment/cd-basics/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b1887ade-7ad5-5fe3-af61-6d78c5a2c391","fields":{"path":"/docs/batch-developer-guides/troubleshooting/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Troubleshooting","description":"Troubleshooting Batch Jobs","path":"batch-developer-guides/troubleshooting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"c457deae-ed32-54de-a049-7770e3a325ab","fields":{"path":"/docs/batch-developer-guides/troubleshooting/debugging-task-apps/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Debugging Batch applications","description":"Debugging Batch applications","path":"batch-developer-guides/troubleshooting/debugging-task-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5353c608-5d97-57a4-a736-d1f433cff87a","fields":{"path":"/docs/batch-developer-guides/troubleshooting/debugging-scdf-tasks/","version":"1.1.0.SNAPSHOT","category":"batch-developer-guides"},"frontmatter":{"title":"Debugging Batch applications deployed by Data Flow","description":"Debugging Batch applications deployed by Data Flow","path":"batch-developer-guides/troubleshooting/debugging-scdf-tasks/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"725e0e0f-7cd9-5f2a-bcab-b945ccf302c3","fields":{"path":"/docs/feature-guides/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Feature guides","description":"High level overview of Data Flow Features","path":"feature-guides/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b668974e-caee-5353-b9da-f892b2541810","fields":{"path":"/docs/feature-guides/general/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"General","description":"General Features in Data Flow","path":"feature-guides/general/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bfd9e556-3733-532e-b587-7a491b45fd3a","fields":{"path":"/docs/feature-guides/general/application-metadata/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Application Metadata","description":"Create and use application properties metadata","path":"feature-guides/general/application-metadata/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"01a83a22-b8d8-5f7a-944a-5d18ed71f844","fields":{"path":"/docs/feature-guides/streams/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Streams","description":"Stream Features in Data Flow","path":"feature-guides/streams/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"bc88a57f-5ead-5fd3-af41-f54dd1057eff","fields":{"path":"/docs/feature-guides/streams/deployment-properties/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Deployment Properties","description":"Initiate a stream deployment with deployment property overrides","path":"feature-guides/streams/deployment-properties/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"7bdab6bf-0057-5fc9-ab6d-997027d023ba","fields":{"path":"/docs/feature-guides/streams/function-composition/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Composing Functions","description":"Daisy-chain Java functions in an existing Spring Cloud Stream application","path":"feature-guides/streams/function-composition/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ed07b36f-0627-57ab-a93d-cb450883437c","fields":{"path":"/docs/feature-guides/streams/named-destinations/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Named Destinations","description":"Use the Named Destinations to interact with the Topics/Queues directly","path":"feature-guides/streams/named-destinations/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"e6150ca7-7101-55aa-bded-afc7773ab000","fields":{"path":"/docs/feature-guides/streams/monitoring/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Stream Monitoring","description":"Monitoring streaming data pipelines with Prometheus and InfluxDB","path":"feature-guides/streams/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"7222ffcd-fd1f-5534-801b-ae813d95519d","fields":{"path":"/docs/feature-guides/streams/stream-application-dsl/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Stream Application DSL","description":"Learn how to use the Stream Application DSL","path":"feature-guides/streams/stream-application-dsl/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"59e1ee0d-8052-5d4d-9313-c6f9f6d82624","fields":{"path":"/docs/feature-guides/streams/labels/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Labeling Applications","description":"Label the stream applications to uniquely interact with them","path":"feature-guides/streams/labels/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9920ad80-48f1-50c9-9275-e6a4bb2b0ebb","fields":{"path":"/docs/feature-guides/streams/application-count/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Application Count","description":"Initiate stream deployment with multiple application instances","path":"feature-guides/streams/application-count/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"95edbb8c-cef8-5869-b71a-5dbdffccc74c","fields":{"path":"/docs/feature-guides/streams/fanin-fanout/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Fan-in and Fan-out","description":"Publish and subscribe to multiple destinations using the fan-in and fan-out capabilities","path":"feature-guides/streams/fanin-fanout/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"0436a379-399f-55aa-8caa-0f7381ea4d70","fields":{"path":"/docs/feature-guides/streams/partitioning/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Data Partitioning","description":"Learn more about data partitioning support to build stateful streaming data pipelines","path":"feature-guides/streams/partitioning/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"8b8b0dd9-9f2d-5fe2-a6f7-946f38490735","fields":{"path":"/docs/feature-guides/streams/scaling/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Scaling","description":"Scaling streaming data pipeline with Spring Cloud Data Flow","path":"feature-guides/streams/scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"844e26f1-494d-54a9-8e04-7c8cf7a217ff","fields":{"path":"/docs/feature-guides/streams/java-dsl/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Java DSL","description":"Programmatically create streams using the Java DSL","path":"feature-guides/streams/java-dsl/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d89b1c27-b48e-5cb8-9b73-03080ae245dd","fields":{"path":"/docs/feature-guides/streams/taps/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Tapping a Stream","description":"Create a stream from another stream without interrupting the data processing","path":"feature-guides/streams/taps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"95ba324d-e79b-5fb8-a887-46f479e0ef0d","fields":{"path":"/docs/feature-guides/batch/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Batch","description":"Batch Features in Data Flow","path":"feature-guides/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"3fc82921-18fe-59b0-8e2e-48badfd9482d","fields":{"path":"/docs/feature-guides/batch/deployment-properties/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Deployment Properties","description":"Initiate a Batch deployment with deployment property overrides","path":"feature-guides/batch/deployment-properties/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"32367cc7-7c6c-55de-84a5-a4377abe5ec8","fields":{"path":"/docs/feature-guides/batch/scheduling/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Scheduling Batch Jobs","description":"Learn how to schedule Batch Jobs","path":"feature-guides/batch/scheduling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a56d78fd-7d1f-58f4-8a64-a660b350f5a0","fields":{"path":"/docs/feature-guides/batch/partitioning/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Remote Partitioned Batch Job","description":"Learn more about partitioning support for Batch Jobs","path":"feature-guides/batch/partitioning/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"72583cff-6bbe-5764-95c8-2b351a2b989b","fields":{"path":"/docs/feature-guides/batch/monitoring/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Task Monitoring","description":"Monitoring task data pipelines with InfluxDB","path":"feature-guides/batch/monitoring/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d95c95c1-e4fd-55aa-bf6a-aa710ecaaefe","fields":{"path":"/docs/feature-guides/batch/restarting/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Restarting Batch Jobs","description":"Learn how to restart Batch Jobs","path":"feature-guides/batch/restarting/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"5af8ec36-e385-584f-a71f-58fdbc579128","fields":{"path":"/docs/feature-guides/batch/composed-task/","version":"1.1.0.SNAPSHOT","category":"feature-guides"},"frontmatter":{"title":"Composed Tasks","description":"Learn how to create and manage composed tasks","path":"feature-guides/batch/composed-task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"67bc7142-3c1d-5999-b3f0-28f60b6f9cce","fields":{"path":"/docs/recipes/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Recipes","description":"Recipes that help solve some common use-cases","path":"recipes/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"57495018-5ab0-5f3d-b90e-cec60aafe00e","fields":{"path":"/docs/recipes/polyglot/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Polyglot","description":"Using multiple programming languages","path":"recipes/polyglot/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1f105736-34d0-50a5-a15b-57d7df62d52a","fields":{"path":"/docs/recipes/polyglot/processor/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Python Stream Processor","description":"Python Application as a Data Flow Stream Processor","path":"recipes/polyglot/processor/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"74562bf5-fa13-5342-92d1-64045e1cf57a","fields":{"path":"/docs/recipes/polyglot/task/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Python Task","description":"Create and Deploy a Python Task","path":"recipes/polyglot/task/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"6cd7b11d-24f2-5a23-9618-dc16593ad0e1","fields":{"path":"/docs/recipes/polyglot/app/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Python Application","description":"Create and Deploy a Python Application in a Stream","path":"recipes/polyglot/app/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b071b155-2da5-5e13-9d1b-1373a219acca","fields":{"path":"/docs/recipes/rabbitmq/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"RabbitMQ","description":"RabbitMQ","path":"recipes/rabbitmq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"4422320f-2a26-5762-aefc-ebe47cabe5b9","fields":{"path":"/docs/recipes/rabbitmq/rabbit-source-sink/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"RabbitMQ as Source and Sink","description":"RabbitMQ as Source and Sink + RabbitMQ binder","path":"recipes/rabbitmq/rabbit-source-sink/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"937f701e-4ae8-51da-b8d8-b029606333b1","fields":{"path":"/docs/recipes/kafka/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Apache Kafka","description":"Kafka","path":"recipes/kafka/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ccdb90a6-2ff0-5f7b-9bf8-f27eb3dd6b90","fields":{"path":"/docs/recipes/kafka/ext-kafka-cluster-cf/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"External Kafka Cluster","description":"Connect to an external Kafka Cluster from Cloud Foundry","path":"recipes/kafka/ext-kafka-cluster-cf/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"43b48f18-cd3a-59bc-a0ec-76caf1870a2e","fields":{"path":"/docs/recipes/kinesis/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Amazon Kinesis","description":"Amazon Kinesis","path":"recipes/kinesis/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"04e94b39-733b-504d-b157-e22049d538f2","fields":{"path":"/docs/recipes/kinesis/simple-producer-consumer/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Amazon Kinesis Binder","description":"A sample of Spring Cloud Stream + Amazon Kinesis Binder in action","path":"recipes/kinesis/simple-producer-consumer/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"efacb7fd-1868-51a0-86b1-dea163aa05ed","fields":{"path":"/docs/recipes/multi-platform-deployment/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Multiple Platform Deployments","description":"Multiple Platform Deployments","path":"recipes/multi-platform-deployment/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a547204f-8273-536d-b631-5e2caa799077","fields":{"path":"/docs/recipes/multi-platform-deployment/multiple-platform-accounts/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Role of Multiple Platform Deployments","description":"A walk-through of multiple platform requirements and the configurations for Cloud Foundry and Kubernetes","path":"recipes/multi-platform-deployment/multiple-platform-accounts","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"ba21954f-491f-55ad-b38a-5f2a548a484f","fields":{"path":"/docs/recipes/scaling/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Scaling","description":"Prometheus and Data Flow to autoscale streaming data pipelines","path":"recipes/scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"74c8179a-6420-50e3-a9fe-a7ac311da03f","fields":{"path":"/docs/recipes/scaling/manual-scaling/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Manual Scaling","description":"Scale applications using SCDF Shell","path":"recipes/scaling/manual-scaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"1ad32761-7748-5dcc-87c3-97ae4d3ffd36","fields":{"path":"/docs/recipes/scaling/autoscaling/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Autoscaling","description":"Autoscale streaming data pipeline with SCDF and Prometheus","path":"recipes/scaling/autoscaling/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b9dbd4b8-36aa-59f9-bd36-e899a6016283","fields":{"path":"/docs/recipes/batch/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Batch","description":"Using Spring Cloud Data Flow with Spring Batch","path":"recipes/batch/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"9a69777e-f1f3-5d52-a06e-e80e509a34b3","fields":{"path":"/docs/recipes/batch/batch-only-mode/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Batch-only Mode","description":"Set up Spring Cloud Data Flow to use only batch and not streams","path":"recipes/batch/batch-only-mode/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"42aa9dd9-531f-59e6-8bc5-69432fa1234d","fields":{"path":"/docs/recipes/batch/sftp-to-jdbc/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"SFTP to JDBC","description":"Ingest Files from SFTP to a JDBC data store using Data Flow and Spring Batch","path":"recipes/batch/sftp-to-jdbc/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"023388a0-221e-5be9-a14d-1ec0bc3a888c","fields":{"path":"/docs/recipes/functional-apps/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Functional Applications","description":"Using Functional Approach in Spring Cloud Stream applications","path":"recipes/functional-apps/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d5ead5aa-ea33-51ec-b5ec-ac5f85a6289a","fields":{"path":"/docs/recipes/functional-apps/scst-function-bindings/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Functional Applications","description":"Configuring the Spring Cloud Stream Functional applications","path":"recipes/functional-apps/scst-function-bindings/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"b6a066e8-6b12-526b-8997-85b6daed059f","fields":{"path":"/docs/recipes/cloud-providers/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"Cloud Providers","description":"Using functionality provided by cloud providers","path":"recipes/cloud-providers/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"d3e47459-1a4b-553f-92c9-109cef0678ca","fields":{"path":"/docs/recipes/cloud-providers/gke-regional-clusters/","version":"1.1.0.SNAPSHOT","category":"recipes"},"frontmatter":{"title":"GKE Regional Clusters","description":"Deploying Spring Cloud Data Flow to a GKE Regional Cluster","path":"recipes/cloud-providers/gke-regional-clusters/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"dce6d220-d80d-5b40-abdd-dccf29666f70","fields":{"path":"/docs/resources/","version":"1.1.0.SNAPSHOT","category":"resources"},"frontmatter":{"title":"Resources","description":"Sample Applications, References Docs, Videos, Blogs...","path":"resources/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"f8865a9e-26ca-54dc-8ea4-2c8375814a34","fields":{"path":"/docs/resources/reference-docs/","version":"1.1.0.SNAPSHOT","category":"resources"},"frontmatter":{"title":"Reference Documentation","description":"Collection of reference guides for Spring Cloud Data Flow","path":"resources/reference-docs/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"2e2318ef-4892-570b-808e-aaaa2018705f","fields":{"path":"/docs/resources/samples/","version":"1.1.0.SNAPSHOT","category":"resources"},"frontmatter":{"title":"Samples","description":"Collection of samples","path":"resources/samples/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"a8f33f41-7d90-5f9f-bc12-86676b11c030","fields":{"path":"/docs/resources/faq/","version":"1.1.0.SNAPSHOT","category":"resources"},"frontmatter":{"title":"Frequently Asked Questions","description":"","path":"resources/faq/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"661b356d-d6cd-5d2c-8c09-da1e48979b83","fields":{"path":"/docs/applications/","version":"1.1.0.SNAPSHOT","category":"applications"},"frontmatter":{"title":"Applications","description":"Using stream and task applications","path":"applications/","meta_title":null,"meta_description":null,"keywords":null}}},{"node":{"id":"060e37c9-d454-519f-ab38-77781d2c00af","fields":{"path":"/docs/applications/pre-packaged/","version":"1.1.0.SNAPSHOT","category":"applications"},"frontmatter":{"title":"Pre-packaged Applications","description":"Pre-packaged stream and task applications","path":"applications/pre-packaged","meta_title":null,"meta_description":null,"keywords":["application","pre-packaged"]}}}]},"page":{"html":"<h1 id=\"installing-by-using-single-node\" style=\"position:relative;\"><a href=\"#installing-by-using-single-node\" aria-label=\"installing by using single node permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Installing by Using Single Node</h1>\n<p>Spring Cloud Data Flow provides a Docker Compose file to let you quickly bring up Spring Cloud Data Flow, Skipper, MySQL and Apache Kafka.\nThe additional <a href=\"/docs/installation/local/docker-customize/\">customization</a> guides help to extend the basic configuration, showing how to switch the binder to RabbitMQ, use different database, enable monitoring more.</p>\n<p>Also, when doing development of custom applications, you need to enable the Docker containers that run the Data Flow and the Skipper servers to see your local file system. The <a href=\"#accessing-the-host-file-system\">Accessing the Host File System</a> chapter below shows how to do that.</p>\n<div class=\"admonition important\"><p>It is recommended to upgrade to the <a href=\"https://docs.docker.com/compose/install/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">latest</a> <code class=\"language-text\">docker</code> and <code class=\"language-text\">docker-compose</code> versions. This guide is tested with Docker Engine: <code class=\"language-text\">19.03.5</code> and docker-compose: <code class=\"language-text\">1.25.2</code>.</p></div>\n<div class=\"admonition important\"><p>Configure your Docker daemon with at least <code class=\"language-text\">8 GB</code> of memory! On Windows or Mac you can use the Docker Desktop's <code class=\"language-text\">Preferences/Resource/Advanced</code> menu to set the Memory.</p></div>\n<p>For the impatient, here is a quick start, single-line command:</p>\n<div class=\"tabs\"><div class=\"tabs-headers\"><a onClick=\"changeTab(event, 0);return false;\" class=\"tab-item active\">Linux / OSX</a><a onClick=\"changeTab(event, 1);return false;\" class=\"tab-item \">Windows (Cmd)</a></div><div class=\"tabs-items\"><div class=\"tab-item active\"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://raw.githubusercontent.com/spring-cloud/spring-cloud-dataflow/master/spring-cloud-dataflow-server/docker-compose.yml<span class=\"token punctuation\">;</span> <span class=\"token punctuation\">\\</span>\n<span class=\"token assign-left variable\">DATAFLOW_VERSION</span><span class=\"token operator\">=</span><span class=\"token number\">2.6</span>.0.BUILD-SNAPSHOT <span class=\"token assign-left variable\">SKIPPER_VERSION</span><span class=\"token operator\">=</span><span class=\"token number\">2.5</span>.0.BUILD-SNAPSHOT <span class=\"token punctuation\">\\</span>\ndocker-compose up</code></pre></div>\n      </div></div><div class=\"tab-item \"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">curl</span> https://raw.githubusercontent.com/spring-cloud/spring-cloud-dataflow/master/spring-cloud-dataflow-server/docker-compose.yml -o docker-compose.yml <span class=\"token operator\">&amp;</span> <span class=\"token builtin class-name\">set</span> <span class=\"token assign-left variable\">DATAFLOW_VERSION</span><span class=\"token operator\">=</span><span class=\"token number\">2.6</span>.0.BUILD-SNAPSHOT<span class=\"token operator\">&amp;</span> <span class=\"token builtin class-name\">set</span> <span class=\"token assign-left variable\">SKIPPER_VERSION</span><span class=\"token operator\">=</span><span class=\"token number\">2.5</span>.0.BUILD-SNAPSHOT<span class=\"token operator\">&amp;</span> docker-compose up</code></pre></div>\n      </div></div></div></div>\n<p>Detailed instructions of how to configure and start Spring Cloud Data FLow using Docker Compose are provided below.</p>\n<h2 id=\"downloading-the-docker-compose-file\" style=\"position:relative;\"><a href=\"#downloading-the-docker-compose-file\" aria-label=\"downloading the docker compose file permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Downloading the Docker Compose File</h2>\n<p><a href=\"https://raw.githubusercontent.com/spring-cloud/spring-cloud-dataflow/master/spring-cloud-dataflow-server/docker-compose.yml\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Click here</a> to get the installation Docker Compose file or use the <a href=\"https://www.gnu.org/software/wget/manual/wget.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">wget</a> or <a href=\"https://curl.haxx.se/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">curl</a> tools to download it:</p>\n<div class=\"tabs\"><div class=\"tabs-headers\"><a onClick=\"changeTab(event, 0);return false;\" class=\"tab-item active\">wget</a><a onClick=\"changeTab(event, 1);return false;\" class=\"tab-item \">curl</a></div><div class=\"tabs-items\"><div class=\"tab-item active\"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://raw.githubusercontent.com/spring-cloud/spring-cloud-dataflow/master/spring-cloud-dataflow-server/docker-compose.yml</code></pre></div>\n      </div></div><div class=\"tab-item \"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">curl</span> https://raw.githubusercontent.com/spring-cloud/spring-cloud-dataflow/master/spring-cloud-dataflow-server/docker-compose.yml -o docker-compose.yml</code></pre></div>\n      </div></div></div></div>\n<div class=\"admonition tip\"><p><a href=\"/docs/installation/local/docker-customize/\">Docker Compose Customization</a> guides provide additional files that can be combined with the basic docker-compose.yml to extend or alter its configuration.</p></div>\n<h2 id=\"starting-docker-compose\" style=\"position:relative;\"><a href=\"#starting-docker-compose\" aria-label=\"starting docker compose permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Starting Docker Compose</h2>\n<p>From within the <code class=\"language-text\">docker-compose.yml</code> directory run:</p>\n<div class=\"tabs\"><div class=\"tabs-headers\"><a onClick=\"changeTab(event, 0);return false;\" class=\"tab-item active\">Linux / OSX</a><a onClick=\"changeTab(event, 1);return false;\" class=\"tab-item \">Windows (Cmd)</a><a onClick=\"changeTab(event, 2);return false;\" class=\"tab-item \">Windows (PowerShell)</a></div><div class=\"tabs-items\"><div class=\"tab-item active\"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">DATAFLOW_VERSION</span><span class=\"token operator\">=</span><span class=\"token number\">2.6</span>.0.BUILD-SNAPSHOT\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">SKIPPER_VERSION</span><span class=\"token operator\">=</span><span class=\"token number\">2.5</span>.0.BUILD-SNAPSHOT\ndocker-compose up</code></pre></div>\n      </div></div><div class=\"tab-item \"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">set</span> <span class=\"token assign-left variable\">DATAFLOW_VERSION</span><span class=\"token operator\">=</span><span class=\"token number\">2.6</span>.0.BUILD-SNAPSHOT\n<span class=\"token builtin class-name\">set</span> <span class=\"token assign-left variable\">SKIPPER_VERSION</span><span class=\"token operator\">=</span><span class=\"token number\">2.5</span>.0.BUILD-SNAPSHOT\ndocker-compose up</code></pre></div>\n      </div></div><div class=\"tab-item \"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"powershell\"><pre class=\"language-powershell\"><code class=\"language-powershell\"><span class=\"token variable\">$Env</span>:DATAFLOW_VERSION=<span class=\"token string\">\"2.6.0.BUILD-SNAPSHOT\"</span>\n<span class=\"token variable\">$Env</span>:SKIPPER_VERSION=<span class=\"token string\">\"2.5.0.BUILD-SNAPSHOT\"</span>\ndocker<span class=\"token operator\">-</span>compose up</code></pre></div>\n      </div></div></div></div>\n<div class=\"admonition tip\"><p>By default, Docker Compose uses the locally available images. Run <code class=\"language-text\">docker-compose pull</code> prior to <code class=\"language-text\">docker-compose up</code> to ensure the latest image versions are downloaded.</p></div>\n<p>once the emitting of log messages on the command prompt stop, open the Spring Cloud Data Flow <a href=\"/docs/concepts/tooling/#dashboard\">Dashboard</a> at <a href=\"http://localhost:9393/dashboard\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">http://localhost:9393/dashboard</a> or use the Shell as explained <a href=\"/docs/installation/local/docker/#shell\">below</a>.</p>\n<p>The following environment variables can be used to configure the <code class=\"language-text\">docker-compose.yml</code>:</p>\n<table>\n<thead>\n<tr>\n<th>Variable name</th>\n<th>Default value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code class=\"language-text\">DATAFLOW_VERSION</code></td>\n<td>(required)</td>\n<td>Data Flow Server version to install. E.g. <code class=\"language-text\">2.4.0.RELEASE</code> or <code class=\"language-text\">2.6.0.BUILD-SNAPSHOT</code> for the latest version.</td>\n</tr>\n<tr>\n<td><code class=\"language-text\">SKIPPER_VERSION</code></td>\n<td>(required)</td>\n<td>Skipper Server version to install. E.g. <code class=\"language-text\">2.3.0.RELEASE</code> or <code class=\"language-text\">2.5.0.BUILD-SNAPSHOT</code> for the latest Skipper version.</td>\n</tr>\n<tr>\n<td><code class=\"language-text\">STREAM_APPS_URI</code></td>\n<td><a href=\"https://dataflow.spring.io/kafka-maven-latest\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://dataflow.spring.io/kafka-maven-latest</a></td>\n<td>Pre-registered Stream applications. Find <a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#_spring_cloud_stream_app_starters\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">here</a> the available Stream Application Starters links.</td>\n</tr>\n<tr>\n<td><code class=\"language-text\">TASK_APPS_URI</code></td>\n<td><a href=\"https://dataflow.spring.io/task-maven-latest\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://dataflow.spring.io/task-maven-latest</a></td>\n<td>Pre-registered Task applications. Find <a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#_spring_cloud_task_app_starters\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">here</a> the available Task Application Starters links.</td>\n</tr>\n<tr>\n<td><code class=\"language-text\">HOST_MOUNT_PATH</code></td>\n<td>.</td>\n<td>Defines the host machine folder path on be mount. See the <a href=\"#accessing-the-host-file-system\">Accessing the Host File System</a> for further details.</td>\n</tr>\n<tr>\n<td><code class=\"language-text\">DOCKER_MOUNT_PATH</code></td>\n<td><code class=\"language-text\">/root/scdf</code></td>\n<td>Defines the target (in-container) path to mount the host folder to. See the <a href=\"#accessing-the-host-file-system\">Accessing the Host File System</a> for further details.</td>\n</tr>\n</tbody>\n</table>\n<p>The docker-compose.yml configurations expose the following container ports to the host machine:</p>\n<table>\n<thead>\n<tr>\n<th>Host ports</th>\n<th>Container ports</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>9393</td>\n<td>9393</td>\n<td>The port that the Data Flow server listens on. You can use it to reach the Dashboard at <a href=\"http://localhost:9393/dashboard\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">http://localhost:9393/dashboard</a> or the REST API at <a href=\"http://localhost:9393\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">http://localhost:9393</a></td>\n</tr>\n<tr>\n<td>7577</td>\n<td>7577</td>\n<td>The port that the Skipper server listens on. You can use it to reach the Skipper REST api at <a href=\"http://localhost:7577/api\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">http://localhost:7577/api</a></td>\n</tr>\n<tr>\n<td>20000-20105</td>\n<td>20000-20105</td>\n<td>Skipper and Local Deployer are configured to use this port range for all deployed stream applications. That means you can reach the application's actuator endpoints from your host machine. The <code class=\"language-text\">server.port</code> deployment property can be used to override those ports.</td>\n</tr>\n</tbody>\n</table>\n<div class=\"admonition tip\"><p>You can leverage the exposed application ports (e.g. <code class=\"language-text\">20000-20105</code>) in you stream applications to expose certain ports to the host machine. For example, the <code class=\"language-text\">http --server.port=20015 | log</code> stream definition would permit you use <code class=\"language-text\">curl</code> and POST HTTP messages to the <code class=\"language-text\">http</code> source directly from your host machine on the <code class=\"language-text\">20015</code> port.</p></div>\n<h2 id=\"stopping-spring-cloud-data-flow\" style=\"position:relative;\"><a href=\"#stopping-spring-cloud-data-flow\" aria-label=\"stopping spring cloud data flow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Stopping Spring Cloud Data Flow</h2>\n<ol>\n<li>Press <code class=\"language-text\">Ctrl+C</code> to shut down the docker compose process.</li>\n<li>Run the following command to clean the used Docker containers:</li>\n</ol>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">docker-compose down</code></pre></div>\n      </div>\n<p>If errors occur due to old or hanging containers, clean all containers:</p>\n<div class=\"tabs\"><div class=\"tabs-headers\"><a onClick=\"changeTab(event, 0);return false;\" class=\"tab-item active\">Linux / OSX / Windows (PowerShell)</a><a onClick=\"changeTab(event, 1);return false;\" class=\"tab-item \">Windows (Cmd)</a></div><div class=\"tabs-items\"><div class=\"tab-item active\"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">docker stop <span class=\"token variable\"><span class=\"token variable\">$(</span>docker <span class=\"token function\">ps</span> -a -q<span class=\"token variable\">)</span></span>\ndocker <span class=\"token function\">rm</span> <span class=\"token variable\"><span class=\"token variable\">$(</span>docker <span class=\"token function\">ps</span> -a -q<span class=\"token variable\">)</span></span></code></pre></div>\n      </div></div><div class=\"tab-item \"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"basic\"><pre class=\"language-basic\"><code class=\"language-basic\"><span class=\"token keyword\">FOR</span> <span class=\"token operator\">/</span>f <span class=\"token string\">\"tokens=*\"</span> %i <span class=\"token function\">IN</span> <span class=\"token punctuation\">(</span>'docker ps <span class=\"token operator\">-</span>aq'<span class=\"token punctuation\">)</span> <span class=\"token keyword\">DO</span> docker rm %i <span class=\"token operator\">-</span>f</code></pre></div>\n      </div></div></div></div>\n<h2 id=\"shell\" style=\"position:relative;\"><a href=\"#shell\" aria-label=\"shell permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Shell</h2>\n<p>For convenience and as an alternative to the Spring Cloud Data Flow Dashboard, you can use the <a href=\"/docs/concepts/tooling/#shell\">Spring Cloud Data Flow Shell</a>.\nThe shell supports tab completion for commands and application configuration properties.</p>\n<p>If you have started Spring Cloud Data Flow by using Docker Compose, the shell is also included in the <code class=\"language-text\">springcloud/spring-cloud-dataflow-server</code> Docker image.\nTo use it, open another console window and type the following:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">docker <span class=\"token builtin class-name\">exec</span> -it dataflow-server java -jar shell.jar</code></pre></div>\n      </div>\n<p>If you have started the Data Flow server with <code class=\"language-text\">java -jar</code>, you can download and start the shell.\nTo download the Spring Cloud Data Flow Shell application, run the following command:</p>\n<div class=\"tabs\"><div class=\"tabs-headers\"><a onClick=\"changeTab(event, 0);return false;\" class=\"tab-item active\">wget</a><a onClick=\"changeTab(event, 1);return false;\" class=\"tab-item \">curl</a></div><div class=\"tabs-items\"><div class=\"tab-item active\"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">wget</span> https://repo.spring.io/snapshot/org/springframework/cloud/spring-cloud-dataflow-shell/2.6.0.BUILD-SNAPSHOT/spring-cloud-dataflow-shell-2.6.0.BUILD-SNAPSHOT.jar</code></pre></div>\n      </div></div><div class=\"tab-item \"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">curl</span> https://repo.spring.io/snapshot/org/springframework/cloud/spring-cloud-dataflow-shell/2.6.0.BUILD-SNAPSHOT/spring-cloud-dataflow-shell-2.6.0.BUILD-SNAPSHOT.jar -o spring-cloud-dataflow-shell-2.6.0.BUILD-SNAPSHOT.jar</code></pre></div>\n      </div></div></div></div>\n<h2 id=\"accessing-the-host-file-system\" style=\"position:relative;\"><a href=\"#accessing-the-host-file-system\" aria-label=\"accessing the host file system permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Accessing the Host File System</h2>\n<p>If you develop custom applications on your local machine, you need to register them with Spring Cloud Data Flow. Since Data Flow server run inside a Docker container, you need to configure this container to access to your local file system to resolve the applications registration references. In order to deploy those custom applications, the Skipper Server also needs to access them from within its own Docker container.</p>\n<p>By default <code class=\"language-text\">docker-compose.yml</code> mounts the local host folder (e.g. folder where the docker-compose process is started) to a <code class=\"language-text\">/root/scdf</code> folder inside both the <code class=\"language-text\">dataflow-server</code> and the <code class=\"language-text\">skipper</code> containers.</p>\n<div class=\"admonition important\"><p>It is vital that the Data Flow and the Skipper containers use <strong>exactly the same</strong> mount points. This allows applications registration references in Data Flow to be resolved and deployed in Skipper using the same references.</p></div>\n<p>The <code class=\"language-text\">HOST_MOUNT_PATH</code> and <code class=\"language-text\">DOCKER_MOUNT_PATH</code> environment variables (see the <a href=\"#starting-docker-compose\">configuration table</a>) allow you to customize the default host and container paths.</p>\n<p>For example, if the <code class=\"language-text\">my-app-1.0.0.RELEASE.jar</code> is stored in the <code class=\"language-text\">/tmp/myapps/</code> folder on the host machine (<code class=\"language-text\">C:\\Users\\User\\MyApps</code> on Windows), you can make it accessible to the <code class=\"language-text\">dataflow-server</code> and <code class=\"language-text\">skipper</code> containers by setting the <code class=\"language-text\">HOST_MOUNT_PATH</code> like this:</p>\n<div class=\"tabs\"><div class=\"tabs-headers\"><a onClick=\"changeTab(event, 0);return false;\" class=\"tab-item active\">Linux / OSX</a><a onClick=\"changeTab(event, 1);return false;\" class=\"tab-item \">Windows (Cmd)</a><a onClick=\"changeTab(event, 2);return false;\" class=\"tab-item \">Windows (PowerShell)</a></div><div class=\"tabs-items\"><div class=\"tab-item active\"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">HOST_MOUNT_PATH</span><span class=\"token operator\">=</span>/tmp/myapps</code></pre></div>\n      </div></div><div class=\"tab-item \"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">set</span> <span class=\"token assign-left variable\">HOST_MOUNT_PATH</span><span class=\"token operator\">=</span>C:<span class=\"token punctuation\">\\</span>Users<span class=\"token punctuation\">\\</span>User<span class=\"token punctuation\">\\</span>MyApps</code></pre></div>\n      </div></div><div class=\"tab-item \"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token variable\">$Env</span>:HOST_MOUNT_PATH<span class=\"token operator\">=</span><span class=\"token string\">\"C:\\Users\\User\\MyApps\"</span></code></pre></div>\n      </div></div></div></div>\n<p>and follow the <a href=\"/docs/installation/local/docker/#starting-docker-compose\">starting docker-compose</a> instructions to start the cluster.</p>\n<p>See the <a href=\"https://docs.docker.com/compose/compose-file/compose-file-v2/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">compose-file reference</a> for further configuration details.</p>\n<p>Once the host folder is mounted, you can register the app starters (from <code class=\"language-text\">/root/scdf</code>), with the Data Flow <a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#shell\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Shell</a> or <a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#dashboard-apps\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Dashboard</a> by using the <code class=\"language-text\">file://</code> URI schema. The following example shows how to do so:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">app register --type <span class=\"token builtin class-name\">source</span> --name my-app --uri file://root/scdf/my-app-1.0.0.RELEASE.jar</code></pre></div>\n      </div>\n<div class=\"admonition tip\"><p>Use the optional, <code class=\"language-text\">--metadata-uri</code> parameter if a metadata jar is available in the <code class=\"language-text\">/root/scdf</code> folder for the same application.</p></div>\n<p>You can also pre-register the apps directly, by modifying the <code class=\"language-text\">app-import</code> configuration in the docker-compose.yml. For every pre-registered app starer, add an additional <code class=\"language-text\">wget</code> statement to the <code class=\"language-text\">app-import</code> block configuration, as the following example shows:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"yml\"><pre class=\"language-yml\"><code class=\"language-yml\"><span class=\"token key atrule\">app-import</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> alpine<span class=\"token punctuation\">:</span><span class=\"token number\">3.7</span>\n  <span class=\"token key atrule\">command</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">></span><span class=\"token scalar string\">\n    /bin/sh -c \"\n      ....\n      wget -qO- 'https://dataflow-server:9393/apps/source/my-app' --post-data='uri=file:/root/apps/my-app.jar&amp;metadata-uri=file:/root/apps/my-app-metadata.jar\"</span></code></pre></div>\n      </div>\n<p>See the <a href=\"https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#resources-registered-applications\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Data Flow REST API</a> for further details.</p>\n<h3 id=\"maven-local-repository-mounting\" style=\"position:relative;\"><a href=\"#maven-local-repository-mounting\" aria-label=\"maven local repository mounting permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Maven Local Repository Mounting</h3>\n<p>You can develop applications and install them in the local Maven repository (using <code class=\"language-text\">mvn install</code>) while the Data Flow server is running and have immediate access to the new built applications.</p>\n<p>To do this you must mount the host’s local maven repository to the <code class=\"language-text\">dataflow-server</code> and <code class=\"language-text\">skipper</code> containers using a volume called <code class=\"language-text\">/root/.m2/</code>.\nThe Maven Local repository location defaults to <code class=\"language-text\">~/.m2</code> for Linux and OSX and to <code class=\"language-text\">C:\\Users\\{your-username}\\.m2</code> for Windows.</p>\n<p>We can leverage the <code class=\"language-text\">HOST_MOUNT_PATH</code> and <code class=\"language-text\">DOCKER_MOUNT_PATH</code> variables to configure mount volumes like this:</p>\n<div class=\"tabs\"><div class=\"tabs-headers\"><a onClick=\"changeTab(event, 0);return false;\" class=\"tab-item active\">Linux / OSX</a><a onClick=\"changeTab(event, 1);return false;\" class=\"tab-item \">Windows (Cmd)</a><a onClick=\"changeTab(event, 2);return false;\" class=\"tab-item \">Windows (PowerShell)</a></div><div class=\"tabs-items\"><div class=\"tab-item active\"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">HOST_MOUNT_PATH</span><span class=\"token operator\">=</span>~/.m2\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">DOCKER_MOUNT_PATH</span><span class=\"token operator\">=</span>/root/.m2/</code></pre></div>\n      </div></div><div class=\"tab-item \"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">set</span> <span class=\"token assign-left variable\">HOST_MOUNT_PATH</span><span class=\"token operator\">=</span>%userprofile%<span class=\"token punctuation\">\\</span>.m2\n<span class=\"token builtin class-name\">set</span> <span class=\"token assign-left variable\">DOCKER_MOUNT_PATH</span><span class=\"token operator\">=</span>/root/.m2/</code></pre></div>\n      </div></div><div class=\"tab-item \"><div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token variable\">$Env</span>:HOST_MOUNT_PATH<span class=\"token operator\">=</span><span class=\"token string\">\"~\\.m2\"</span>\n<span class=\"token variable\">$Env</span>:DOCKER_MOUNT_PATH<span class=\"token operator\">=</span><span class=\"token string\">\"/root/.m2/\"</span></code></pre></div>\n      </div></div></div></div>\n<p>and follow the <a href=\"/docs/installation/local/docker/#starting-docker-compose\">starting docker-compose</a> instructions to start the cluster.</p>\n<p>Now you can use the <code class=\"language-text\">maven://</code> URI schema and Maven coordinates to resolve jars installed in the host’s maven repository, as the following example shows:</p>\n<div class=\"spring-code\">\n        <button onClick=\"codeToClipboard(event)\" class=\"button button-clipboard\" type=\"button\">Copy</button>\n        <div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">app register --type processor --name pose-estimation --uri maven://org.springframework.cloud.stream.app:pose-estimation-processor-rabbit:2.0.2.BUILD-SNAPSHOT --metadata-uri maven://org.springframework.cloud.stream.app:pose-estimation-processor-rabbit:jar:metadata:2.0.2.BUILD-SNAPSHOT</code></pre></div>\n      </div>\n<p>This approach lets you use applications that are built and installed on the host machine (for example, by using <code class=\"language-text\">mvn clean install</code>) directly with the Spring Cloud Data Flow server.</p>\n<h2 id=\"monitoring\" style=\"position:relative;\"><a href=\"#monitoring\" aria-label=\"monitoring permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Monitoring</h2>\n<p>The basic Data Flow docker-compose configuration does not enable the monitoring functionality for Stream and Task applications. Follow the <a href=\"/docs/installation/local/docker-customize/#prometheus--grafana\">Monitoring with Prometheus and Grafana</a> or <a href=\"/docs/installation/local/docker-customize/#influxdb--grafana\">Monitoring with InfluxDB and Grafana</a> customization guides to learn how to enable and configure the monitoring for Spring Cloud Data Flow.</p>\n<p>To learn more about the monitoring experience in Spring Cloud Data Flow with Prometheus and InfluxDB, see the <a href=\"/docs/feature-guides/streams/monitoring/#local\">Stream Monitoring</a> feature guide.</p>\n<h2 id=\"debugging\" style=\"position:relative;\"><a href=\"#debugging\" aria-label=\"debugging permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Debugging</h2>\n<p>The <a href=\"/docs/installation/local/docker-customize/#debug-stream-applications\">Debug Stream Applications</a> guide, shows how to enables remote debugging for Stream Applications deployed by Data Flow.</p>\n<p>The <a href=\"/docs/installation/local/docker-customize/#debug-data-flow-server\">Debug Data Flow Server</a> guide, shows how extend the docker compose configuration to enables remote Data Flow Server debugging with your IDE such as IntelliJ or Eclipse.</p>\n<p>The <a href=\"/docs/installation/local/docker-customize/#debug-skipper-server\">Debug Skipper Server</a> guide, shows how extend the docker compose configuration to enables remote Skipper Server debugging with your IDE such as IntelliJ or Eclipse.</p>","headings":[{"value":"Installing by Using Single Node","depth":1},{"value":"Downloading the Docker Compose File","depth":2},{"value":"Starting Docker Compose","depth":2},{"value":"Stopping Spring Cloud Data Flow","depth":2},{"value":"Shell","depth":2},{"value":"Accessing the Host File System","depth":2},{"value":"Maven Local Repository Mounting","depth":3},{"value":"Monitoring","depth":2},{"value":"Debugging","depth":2}],"fields":{"path":"/docs/installation/local/single-node/","version":"1.1.0.SNAPSHOT","category":"installation","sourcePath":"pages/1-installation/1-local/1-single-node.md"},"frontmatter":{"title":"Single Node","summary":null,"path":"installation/local/single-node","toc":null,"prevNext":null}}},"pageContext":{"slug":"/docs/installation/local/single-node/","version":"1.1.0.SNAPSHOT","versionPath":""}},"staticQueryHashes":["1084522749","2044043181"]}